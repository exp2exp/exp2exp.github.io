<html><head><meta charset="UTF-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      processEscapes: true
    }
  });</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script async="async" src="https://hypothes.is/embed.js"></script><script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><link href="https://exp2exp.github.io/static/css/firn_base.css" rel="stylesheet" /><link href="https://fonts.gstatic.com" rel="preconnect" /><link href="https://fonts.googleapis.com/css2?family=Ubuntu+Condensed&amp;family=Ubuntu+Mono&amp;family=Ubuntu:wght@300;400&amp;display=swap" rel="stylesheet" /><script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script></head><body><main><article class="content"><h1>Information extraction from SO Q&A items</h1><div><div><section><p><span>We are attempting to extract triples from textual Q&A by using a
Neural Machine Translation approach.</span></p></section><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="idea-is-we-need-a-basic-data-model-from-which-we-can-build-things"><span class="firn-headline-text"><span>Idea is we need a basic data model from which we can build things</span></span></h2><section><ul><li><p><span>User assistants</span></p></li><li><p><span>If we have triples we can do interesting subtasks</span></p></li><li><p><span>What’s a nice little task to solve in workflows w/ text or w/ code?</span></p></li></ul></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="gptbert"><span class="firn-headline-text"><span>GPT/BERT</span></span></h1><section><ul><li><p><span>Are they relevant for this? Or are they just good for prettifying
   text to do fun tricks?</span></p></li></ul></section><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="ontology-papers-in-stanford"><span class="firn-headline-text"><span>Ontology papers in Stanford</span></span></h2><section><p><span>Pinpointing what can and can’t be done. E.g., phrase structure. Linear
probes into the model, correlate weight structure of attention nodes
and classical phrase extractors.  This uses Stanford’s phrase
structure parser (which is based on correct phrase structure
extraction).</span></p><p><span>GPT & BERT have the </span><em><span>beginning</span></em><span> of capturing. Classical embedding
results hold (King is to Queen...).  Pretrained model gets maybe 85%
of the classical task.</span></p><p><span>So, if we get a downstream task (relatively shallow linguistic task
X), then you have an expectation that with 10K examples to fine-tune,
you’ll get a decent outcome.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="deyan’s-prior-notebooks"><span class="firn-headline-text"><span>Deyan’s prior notebooks</span></span></h2><section><p><span>Had borderline reasonable results, extracting triples that were
linguistically plausible SVO triples.  But these weren’t business
ready.  It would get confused about extracting only a fragment
(‘elephant’, not ‘pink elephant’).  Still, this gives validation that
concept extraction works.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="play-with-rewrite-rules?"><span class="firn-headline-text"><span>Play with rewrite rules?</span></span></h2><section><ul><li><p><span>Michael Kohlhase’s thesis deals with this (using unification)</span></p></li><li><p><span>In language land, rewrites are just translations</span></p></li><li><p><span>In ML, it’s just a model translating things</span></p></li></ul><p><span>In a serious program language setting, Python 3.7, we’ll use the abstract
syntax tree of Python, doing formal bits</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="categorise:-q-or-a?"><span class="firn-headline-text"><span>Categorise: Q or A?</span></span></h2><section><ul><li><p><span>A/B test explanations?</span></p></li><li><p><span>“Grammarly” for SO (but this is 2-3 times harder than improving documentation)</span></p></li></ul></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="extracting-metadata"><span class="firn-headline-text"><span>Extracting metadata</span></span></h2><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="given-text-as-question-answer,-provide-as-much-metadata-as-possible"><span class="firn-headline-text"><span>Given text as question answer, provide as much metadata as possible</span></span></h3></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="instead-of-triples,-care-about-words-that-may-not-even-be-in-there"><span class="firn-headline-text"><span>Instead of triples, care about words that may not even be in there</span></span></h3></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="google-photos"><span class="firn-headline-text"><span>Google Photos</span></span></h3><section><p><span>They’ve used individual classifiers for any label of interest “church”, “cheesecake”.
They have many NN classifiers, one for each photo.</span></p><p><span>This shines b/c you can annotate people with names.  If I search for
“me plus my parents” I get exactly what I’d want.</span></p><p><span>This would be a bit intense if you have 1 million data for 2m gigabytes of address space.</span></p></section></div></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="map:-q’s-to-a’s-and-vice-versa"><span class="firn-headline-text"><span>Map: Q’s to A’s and vice versa</span></span></h2></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="identify-duplicate-answers"><span class="firn-headline-text"><span>Identify duplicate answers</span></span></h2><section><p><span>If someone answers, people don’t ask.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="identify-relevant-answers"><span class="firn-headline-text"><span>Identify relevant answers</span></span></h2><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="cl:-match-“i’m-buying-what-someone-is-selling”"><span class="firn-headline-text"><span>CL: match “I’m buying what someone is selling”</span></span></h3></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="iterating-or-recursively-doing-this-as-a-tree"><span class="firn-headline-text"><span>Iterating or recursively doing this as a tree</span></span></h3><section><ul><li><p><code>(A (B (C D E F)))</code></p></li></ul><p><span>(This is pretty easy to evaluate.)</span></p><p><span>E.g. with Wikipedia internal links: do they reference as related or...</span></p><p><span>On SO there’s a second aspect: “I’m trying to achieve X but I’m
failing in this way.”  The answer is a rewrite.  Not a dependency but
it’s about mastery.</span></p><p><span>“Recommending comprehensive solutions for programming tasks by mining
crowd knowledge.”</span></p><p><span>Link text + surrounding context: does the target page link back?
And if it does link back they are of mutual importance.</span></p><p><span>Context will tell whether it’s a general or specific concept.</span></p><p><span>JC: Q/A can also be seen as a link.</span></p></section></div></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="route-questions-based-on-expertise"><span class="firn-headline-text"><span>Route questions based on expertise</span></span></h2><section><p><span>This is something that people have looked at.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="why-have-a-man-page-if-you-could-turn-so-into-man-pages-that-interact?"><span class="firn-headline-text"><span>Why have a man page if you could turn SO into man pages that interact?</span></span></h2><section><p><span>In general docs are trash, so you google and use SO for tasks.
Pandas docs are almost intentionally obfuscated, the examples are useless.</span></p><p><span>Competing with Google-for-StackOverflow isn’t a great plan</span></p><p><span>But could I improve the documentation itself?</span></p></section><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="autogenerate-better-documentation-for-python"><span class="firn-headline-text"><span>Autogenerate better documentation for python</span></span></h3><section><ul><li><p><span>Python is ubiquitous and there are a lot of SO</span></p></li><li><p><span>There could also be demand</span></p></li><li><p><span>Ontology could turn into TOC for the guide</span></p></li></ul></section></div></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="validating-gpt-as-usable-or-not-usable-in?"><span class="firn-headline-text"><span>Validating GPT as usable or not usable in...?</span></span></h2><section><p><span>There’s a terminal that uses GPT. You could describe your CSS
and it changed an English description into a webpage template.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="given-a-schema-it-can-generate-a-query"><span class="firn-headline-text"><span>Given a schema it can generate a query.</span></span></h2><section><p><span>There are text summarisation quips (e.g., generate abstracts).</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="if-you-extracted-information-this-way-we-could-use-stan-to-validate-a-hypothesis"><span class="firn-headline-text"><span>If you extracted information this way we could use STAN to validate a hypothesis</span></span></h2><section><p><span>E.g. get estimates about sizes of groups on SO.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="pie-in-the-sky"><span class="firn-headline-text"><span>Pie-in-the-sky</span></span></h2><section><p><span>You could use nonparametric Bayesian models to ‘tame’ a neural network
and make it interpretable.  You can put it into an end-to-end
differentiable system, alternate generalisable with model structure.</span></p><p><em><span>Tangled Program Graphs</span></em></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="“hate-speech”"><span class="firn-headline-text"><span>“Hate speech”</span></span></h2><section><p><span>"How do I solve this sort in Python"
If I reply enough with Haskell, you can see I’m galling him... this is so much easier in Haskell.
You can go w/ stable differences when these 2 user are interacting.</span></p><p><span>This is a high-quality answer but in the context of all the answers
and questions, you find it’s actually hate speech.</span></p></section><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="friendworld"><span class="firn-headline-text"><span>Friendworld</span></span></h3><section><p><span>It’s about frogs that are friendly. This is a Pepe the frog
meme. They’d post melancholy or fun frog...</span></p><p><span>With interspersed nazi shit.</span></p><p><span>Audioplayers can be completely destroyed by playing a certain record.</span></p><p><span>If you’re looking for honest learning exachanges they are more mundane.</span></p><p><span>E.g., </span><strong><span>account for poor wording</span></strong><span>.</span></p></section></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="but-humans-are-good-at-understanding-this-but-computers-aren’t"><span class="firn-headline-text"><span>BUT... Humans are good at understanding this but computers aren’t.</span></span></h3><section><p><span>People were pointing out the subtle stuff, the problem was that there
wasn’t enough investment to do anything about it.</span></p><p><span>In Germany, Twitter filters holocaust denial; even the stuff they
(could) detect they don’t remove.  In the US, if you report it,
they’ll deny it.  (It’s a ‘prior restraint’ thing... it’s complicated
if you’re responding to someone’s complaint.)</span></p><p><span>Look at two Nazi related words and see if they form a hashtag.</span><code>#jewspiracy</code><span> etc.</span></p><p><span>Filters are however very difficult.</span></p><ul><li><p><span>An automated white-knight that did the responding for you</span></p></li><li><p><span>But they want you to engage...</span></p></li></ul><p><span>You could do tricks, people started using </span><code>#proudboys</code><span> for something
else.</span></p></section></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="example:-how-does-responding-to-hate-speech-influence-things?"><span class="firn-headline-text"><span>Example: how does responding to hate speech influence things?</span></span></h3><section><p><span>Study tracking activity and challenges as to whether people continue
posting hate speech.</span></p></section></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="“consider-writing-this-in-a-more-assertive-way”"><span class="firn-headline-text"><span>“Consider writing this in a more assertive way”</span></span></h3><section><p><span>I wonder if possibly...</span></p><p><span>Guess the degree of someone by reading their email</span></p></section></div></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="automatically-generating-docs-from-type-signature"><span class="firn-headline-text"><span>Automatically generating docs from type signature</span></span></h2><section><p><span>Maybe going for a language with static types could be a way to combine
free association in the structured data.</span></p><p><span>This is more robust than "write language and get code out."</span></p><p><span>“Write code with a bug, get SO Q&A back” (Crokage?)</span></p><p><span>Starting with working code.
How would you generate failing code.
How would you generate failing unit tests?
(E.g., “fuzzers” that generate near arbitrary run-ti)
Put in integers, get output. Generate wrong unit tests.</span></p></section></div></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="overall-commments"><span class="firn-headline-text"><span>Overall commments</span></span></h1><section><p><span>These are translation or compression style problems.</span></p><p><span>Code generation demos are pretty suspicious: GPT3 doesn’t make
off-by-one errors, it uses completely different function syntax.</span></p><p><span>Like the motivation behind it. Z was recently criticising
auto-generation of query program. The amount of time it takes to debug
the query.</span></p><p><span>“Count all the listings” but rather queried the database’s AirBnB
table. What if there are multiple tables w/ similar names?</span></p><p><span>If you put leashes on these things, using solid methods.</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="we-didn’t-get-one-simple"><span class="firn-headline-text"><span>We didn’t get one simple</span></span></h1></div></div></div><div><hr /><div class="backlinks"><h4>Backlinks to this document:</h4><ul class="firn-backlinks"><li class="firn-backlink"><a href="https://exp2exp.github.io/20200905125023-which_model_construction_process_works_as_a_whole">Which model construction process works as a whole?</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/gather_data_via_stack_exchange_apis">Gather data via Stack Exchange APIs</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/initial_ml_baseline_e_g_match_q_a">Initial ML baseline, e.g., match Q-A</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/hierarchical_ml_for_content_extraction">Hierarchical ML for content extraction</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/ml_nlp_bootcamp">ML/NLP bootcamp</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/20200905124405-construct_critique_improve_models_of_the_creative_process">Construct, critique, improve models of the creative process</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/index">index</a></li></ul></div></div></article></main></body><script>anchors.options = {
                               visible: 'always',
                               placement: 'left',
                               icon: '§'
                               };
            anchors.add('h2');
            anchors.add('h3');
            anchors.add('h4');
            anchors.add('h5');</script></html>