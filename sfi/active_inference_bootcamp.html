<html><head><meta charset="UTF-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      processEscapes: true
    }
  });</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><link href="https://exp2exp.github.io/static/css/firn_base.css" rel="stylesheet" /></head><body><main><article class="content"><h1>Active Inference bootcamp</h1><div><div><section><p><span>Cameron talked a bit about active inference, and his Bayesian stats
background is relevant to making sense of what’s going on in here.
Lots of other papers are available, including some by Beren Millidge
if we wanted to start making models of agents.</span></p><p><span>We could also/alternatively think about these models in terms of
Tangled Program Graphs or some other reinforcement learning paradigm.
E.g., Zans and I talked about making an upvoting bot.  If we could
moreover learn the actual features that go into good questions and
answers, then those could be used on the generative side too.</span></p></section></div></div><div><hr /><div class="backlinks"><h4>Backlinks to this document:</h4><ul class="firn-backlinks"><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/sfi">Joe’s Santa Fe Institute proposal (Redux)</a></li><li class="firn-backlink"><a href="https://exp2exp.github.io/sfi/hierarchical_ml_for_content_extraction">Hierarchical ML for content extraction</a></li></ul></div></div></article></main></body></html>