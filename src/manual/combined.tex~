% Created 2020-10-18 Sun 19:29
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[a4paper,bindingoffset=0.2in,left=1in,right=1in,top=1in,bottom=1in,footskip=.25in]{geometry}
\usepackage[dvipsnames]{xcolor}
\usepackage{fontspec}
\usepackage[math-style=french]{unicode-math}
\usepackage{mathtools}
\setmathfont[math-style=upright]{DejaVu Sans Mono}
\setmonofont[scale=.8,Color=blue]{Ubuntu Mono}
\newfontfamily{\mm}[scale=.8,Color=red]{DejaVu Sans Mono}
\setmainfont[BoldFont=EB Garamond,BoldFeatures={Color=ff0000}]{EB Garamond}
\newcommand{\hookuparrow}{\mathrel{\rotatebox[origin=c]{90}{$\hookrightarrow$}}}
\usepackage{fix-abstract}
\definecolor{pale}{HTML}{fffff8}
\definecolor{orgone}{HTML}{83a598}
\definecolor{orgtwo}{HTML}{fabd2f}
\definecolor{orgthree}{HTML}{d3869b}
\definecolor{orgfour}{HTML}{fb4933}
\definecolor{orgfive}{HTML}{b8bb26}
\definecolor{gruvbg}{HTML}{1d2021}
\newenvironment*{emptyenv}{}{}
\usepackage{sectsty}
\sectionfont{\normalfont\color{red}\selectfont}
\subsectionfont{\normalfont\selectfont}
\paragraphfont{\normalfont\selectfont}
\subsubsectionfont{\normalfont\selectfont\color{black!50}}
\author{Joe Corneli}
\date{\today}
\title{Hyperreal Enterprises: Roadmap}
\hypersetup{
 pdfauthor={Joe Corneli},
 pdftitle={Hyperreal Enterprises: Roadmap},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.0.50 (Org mode 9.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\begin{abstract}
\noindent This document can be thought of as an informal outline of a “\emph{tactic state}”.  On a technical level, the upstream source for this material is an Org Roam graph.  The “Wiki” section contains instructions for accessing the material and generating derived formats, such as the Org Agenda.
\end{abstract}

\setcounter{tocdepth}{2}
\tableofcontents
\section{Hyperreal Enterprises: Roadmap}
\label{sec:org3781bc1}

\subsection{Preface}
\label{sec:org6999281}
This document synthesises a \href{http://www.peeragogy.org/pattern-roadmap.html}{Roadmap} (and perhaps also a \href{http://scrumbook.org/value-stream/product-roadmap.html}{Product
Roadmap}) for Hyperreal Enterprises, Ltd.  The Roadmap is being written
inside \href{https://github.com/org-roam/org-roam}{Org Roam} (an \href{https://www.gnu.org/software/emacs/}{Emacs} package), and shared via Git on repo.or.cz.
This document can be thought of and edited as a \hyperref[sec:org8bba941]{Wiki}, from which other
downstream formats can be derived.  A narrative introduction follows.
To skip it, browse ahead to \hyperref[sec:orgce48d63]{Top}.

\subsection{Introduction}
\label{sec:org21aea3f}

\subsubsection{Applying AI to technical fields is a huge opportunity.}
\label{sec:org32a1b7e}

It’s striking that in computer programming work, \emph{collective
intelligence} is used almost everywhere, but artificial intelligence is
used almost nowhere.  AI can kick butt at Chess and Go, but university
courses are still taught by human professors.  Surely, AI that could
write code at a human level would be a valuable thing\ldots{}

\subsubsection{But where’s the human-level AI for coding?}
\label{sec:org4313136}

A research agenda around “AI for programming” was already spelled out
by Alan Turing in the late 1940s.  It is only relatively recently that
we have massive amounts of relevant data to work with.  Code
completion and code generation tools are some of the “low hanging
fruit” of this domain.  We think that something much more substantial
is around the corner.

\subsubsection{We are looking at this problem as an informal open source R\&D collective.}
\label{sec:orgd26372c}

Our team brings together applied experience in Natural Language
Processing (NLP), computational modelling, online communities,
physics, biology, mathematics, and statistics.  We’ve been getting
together for daily coffee chats, and sharing information and skills
with each other in online seminars.  Sometimes we bring in guest
speakers.  We hope as time goes by our chats will coalesce into notes,
blog posts, papers, and working prototypes.  We aren’t promising a
schedule of deliverables — because we’re all volunteers — and we’re
doing this for fun and interest.  But we do plan to share what we’re
learning as we go along!

\subsubsection{Broadly, the steps we have in mind go from data, to models, to AI agents.}
\label{sec:org25e340f}

We plan to document our progress (or lack thereof) on this blog.  As a
very rough outline, this is what we expect to look at:

\begin{itemize}
\item We plan to use contemporary information extraction methods to derive computationally meaningful material from Stack Exchange Q\&A, Github Issues, and programmers’ discussions, along with code. To do this, we will combine general purpose language models, like BERT, and a knowledge graph approach.

\item We plan to use category theoretic methods as a glue that can hold together a range of computational models, including models of programs and the process of computer programming. \href{https://arxiv.org/pdf/1807.05691}{Monocl} is an existing process modelling language that has been used to create an abstraction layer over a collection of \href{https://www.datascienceontology.org/}{data science programs}. We plan to generalise this.

\item Ultimately, we plan to install these models in computational agents who can then “converse with each other to sharpen their wits,” as Turing anticipated, mirroring contemporary developments in self-play.  However, the specific design of the agents remains an open issue at the moment!  We plan to explore techniques from Bayesian learning, logic programming, and reinforcement learning.
\end{itemize}

\subsubsection{Reflection is part of the process.}
\label{sec:org86641c8}

We’re interested in understanding human behaviour as well as technical
topics: that goes for our own behaviour in particular.  We plan to
post to our blog at least monthly — as long as we keep our discussion
running — using it as a place to reflect on how things are going.
Although we’re grappling with some weighty topics, success is not all
or nothing!  Writing here will mark our progress and be useful in
their own right (e.g., blog posts can feed into research papers or
tools).

\subsubsection{Progress so far}
\label{sec:org3b813d0}
Alongside setting up a blog and drafting an initial anouncement
(voilà!), we’ve updated the website of our affiliated UK-based company
\href{https://hyperreal.enterprises/}{Hyperreal Enterprises} to match the outlines of what we’ve described
here.  As mentioned above, are having regular meetings, which we’ll
record if they look likely to be interesting to a wider audience.
We’ve got nice internal documentation going, via \href{https://github.com/org-roam/org-roam}{Org Roam}, from wich
various derived formats are produced, including a public \href{https://exp2exp.github.io/}{wiki}
generated by \href{https://github.com/theiceshelf/firn}{Firn}.  (We recently sent an abstract to EmacsConf 2020 to
talk about the various other Emacs-based tools we’re using!)

Some of our seminars so far have explored an Open Information
Extraction (with several demo notebooks), and looked at the early
parts of Michael Betancourt’s “Towards a principled Bayesian
workflow”.

Active channels on our Discord server include:
\begin{itemize}
\item \#emacs-cloud-hypernotebooks
\item \#how-to-design-programs
\item \#text-analysis
\item \#model-construction
\item \#knowledge-graph
\end{itemize}

\subsubsection{TL;DR}
\label{sec:org6107bb6}

We are creating AI tools that will process open source information and
build on these in applications such as automated programming.

\section{Top}
\label{sec:orgce48d63}
\subsection{Motivation: For the sake of advancing AI}
\label{sec:org2e94c42}
We are doing this R\&D work partly to make demonstrations of more
advanced AI systems.  We expect that our stance on AI will not
necessarily be a popular one.  But this is an important “minor” strand
of AI research dating back to Alan Turing:

\begin{quote}
``As time goes on the [computer] itself will take over the functions
both of [programmers] and of [users]…The [programmers] are liable to
get replaced because as soon as any technique becomes at all
stereotyped it becomes possible to devise a system of instruction
tables which will enable the electronic computer to do it for
itself. It may happen however that the [programmers] will refuse to do
this. They may be unwilling to let their jobs be stolen from them in
this way. In that case they would surround the whole of their work
with mystery and make excuses, couched in well chosen gibberish,
whenever any dangerous suggestions were made.'' -- Alan Turing, 1947.
\end{quote}

On average, advanced AI would bring in new ways of working, and would
facilitate broad access to high-quality training.  This agenda could
serve to focus the mind of technical workers, but not many are
pursuing it presently.

\subsection{Motivation: Technical experiments become easier}
\label{sec:org9a096bc}

Even in the present time, without relying on any speculative AI
futures to magically appear, we can benefit from pursuing the agenda
above.  Accordingly, we are doing some applied work with existing
software that will give us a set of further tools and levers to work
with.

\subsection{Representative Prior Work}
\label{sec:org0bd6e69}

\subsubsection{PlanetMath}
\label{sec:org63fed45}

\href{https://planetmath.org/}{PlanetMath} users created a reasonably large informal mathematical
knowledge base together.  On the way, we came up with several
technical demos and sketched possible \href{https://github.com/holtzermann17/planetmath-docs/labels/PREVIEW}{previews} for upcoming features.
One possible direction of work we looked at would be to focus on
building a comprehensive category theory knowledge base.

\subsubsection{Modelling the way mathematics is actually done}
\label{sec:org7d771e9}

In \href{https://www.newton.ac.uk/files/preprints/ni17003.pdf}{this paper}, we talked about how mathematics is situated somewhere
in between ‘games’ and ‘storytelling’ in its complexity.  We proposed
to build computational models of informal mathematical reasoning.
Subsequent work continued on in this direction, using ideas from
\href{https://www.sciencedirect.com/science/article/pii/S0004370217300267}{dialogue games} and \href{https://link.springer.com/article/10.1007/s10503-018-9474-x}{argumentation theory more broadly}.

\subsection{A sketch of a plan}
\label{sec:org5c53951}

So, having gotten together around these ideas, we’re having online
chat, frequent short meetings.  We’ve talked about maintaining a blog
that would describe what we’re learning and developing.  So, roughly
speaking, we will try to develop a curriculum through the blog.  We
also have this wiki, that any of us can edit, which we can use as a
staging ground for more developed blog posts.  Our thought was that
blog posts might move in the direction of more developed outputs,
whether products or research papers.  We want to use some ideas
adapted from Scrum to build a shared awareness of what’s going on.
However, we want to be careful not to become “managerial” since
everyone is currently here as a volunteer, working on topics of his or
her own interest.  We want to provide mutual support and fun.
Reflection, whether in writing, or by recording and listening again to
conversations, should help with that.  We are not constraining things
to come out in a purely structured curriculum, or any other form of
product development.  “Users” and “customers” may appear as we release
things we are happy with and expand our little community.

\begin{quote}
“Rousseau says, someone who has been properly educated will be engaged
in society, but relate to his or her fellow citizens in a natural way.
\ldots{} We naturally look after our own
preservation and interests.  By contrast, \emph{amour-propre} is an unnatural
self-love that is essentially relational. \ldots{} Thus, \emph{amour-propre} can
contribute positively to human freedom and even virtue. Nevertheless,
\emph{amour-propre} is also extremely dangerous because it is so easily
corruptible. \ldots{} In its corrupted form, \emph{amour-propre} is the source of
vice and misery, and results in human beings basing their own self
worth on their feeling of superiority over others.” — \href{https://iep.utm.edu/rousseau/}{IEP}
\end{quote}

\subsection{A possible formulation: short correlated sprints as opposed to random behaviour}
\label{sec:orgf3edc37}

“Two people working together 4 hours a week for two weeks” could serve
as an approximate unit of work.  Once we have amassed a few outputs
from this kind of effort, we will have some evidence of the kinds of
things that we can realistically achieve.  So far, our workflow has
been more based on solo activities and informal conversations, but
short robust team-ups continue to be an option!

\begin{quote}
Hypothetical conversation: \emph{In my next post I want to integrate something that I learned from you about PL.  I want to drive in the direction of synthesis, as hard as I know how to right now.  This depends on everyone having free time to invest in this.  Start a blog where we think about what's the overlap in terms of learning?}
\end{quote}
\section{Why not what}
\label{sec:orge201913}
Our purpose:

\begin{itemize}
\item \textbf{We want to make the knowledge economy accessible to everyone.}
\item \textbf{Our long-term vision is computational intelligence based on collective intelligence.}
\end{itemize}
\subsection{Teach arbitrary coding}
\label{sec:org5c24a9e}
This would be an abstraction over teaching basic programming and
knowledge graphs.

\subsubsection{Feature: Production system}
\label{sec:org9f71c2f}

We’ve started to build a simple production system that can be used to
detect errors in subtraction (reimplementing some classic work). We
were thinking that something similar could be used to detect other
kinds of errors (so, for debugging, teaching), and to support other
kinds of reasoning processes (e.g., turning Q’s into A’s in a
question-answering system).

We previously did a little exploratory work, with similar intent, using
polygraphs as input, in the workshop paper
\emph{Modelling the Way Mathematics Is Actually Done}.

\begin{enumerate}
\item Demo application: Reimplementing classic rules to model subtraction
\label{sec:org7777ca9}

We looked at a classic paper about “subtraction on Mars” and it seems
that reimplementing it might be the best way to go.
\end{enumerate}

\subsection{How to Design Programs}
\label{sec:orgd1b20f7}
We were thinking of \emph{How to Design Programs} (HtDP) as a potential
basis for this work.  We would want to respect category theoretic
concepts in the presentation.  We would expect to find analogues in
settings like Bayesian modelling.

We could proceed by looking at relationships with argumentation
theory, thinking about how to do this in a theoretically consistent
way.  Once we have a definition of the programming language we’re
going to use, we can then do argumentation over that.

Another strategy would be to develop a DSL for HtDP ideas, which we
could then reuseq to generate patterns for learning how to design
various structures (say, web pages or probabilistic programs).  To do
this well you’d need ways to express ‘recipes’.  For example, an MVP
might be based on representing HtDP-style recipes using sequent
calculi for session types.  These represent interactive protocols.

You’d use cut-elimination to have two players interact (using
something like the \textbf{\textbf{Lakatos Game diagram}}).  But what formalism
would you use?  E.g., \emph{geometry of interaction in linear logic} has
been used for this kind of thing, but could it be used here?  With a
suitable formalism in place we would then imagine that a computer
programming agent would just follow the “Lakatos Game” style HtDP
script.  So, this would contribute to the development of agent models
for programming and program-related Q\&A.

\subsubsection{Related work}
\label{sec:org5864561}

\begin{itemize}
\item General theory-informed algorithms (e.g., apply category theory to scientific models).
\item K framework: Have transformations for any language you define in it.
\item HtDP is similar applied to programming teaching.  Start with PL theory and then find universal things.
\item How can we define statistics in a general way and then derive things from it?  (E.g., Anglican probabilistic programming?)
\end{itemize}
\section{Construct, critique, improve models of the creative process}
\label{sec:org46cc1b8}
We want tools and processes for working with models, with a particular
emphasis on improved models of the creative process. The reason for
this emphasis is that if we have good models of the creative process,
including the modelling process, we can then apply them to a wide
range of problems!  This prompts reflection on the infrastructure and
tools that we are actually using.

\subsection{Emacs Hyper Notebook}
\label{sec:orgbc09e7d}
We are developing a better way to do “Jupyter notebooks” using Emacs.
This recovers some of the Research Collab ideas developed by Aaron
Krowne. It should integrate features such as writing and task
management (e.g., \emph{Org}) Program evaluation (e.g., \emph{Maxima}),
Typesetting and presentation (e.g., slides via \emph{\LaTeX{}}), and
navigation (e.g., \emph{Org Roam} for displaying topics as a graph).  We
should be clear that the various technologies used are slot-fillers
and they might be replaced with other things, or augmented (e.g.,
\emph{Lean} for formal verification of some of the above?). A useful input
to this process would be implementation of examples without
integration.  This can then be redone in a more integrated fashion.

An integration using existing technologies will have limitations, once
we have this demos then we will see some of the gaps and how more
advanced tech could be useful. (For example, Ray’s work with Gerschom
could turn out to be useful here.)

\begin{enumerate}
\item Some quick thoughts
\label{sec:org8c5e340}

\begin{itemize}
\item If it was sitting inside a web container, then maybe it’s a quickstart thing that comes in a user friendly form.
\item Maybe add menu-bar items to make it look like a web browser.
\item Emacs Maxima interface, we might build on it — for Monday 12th October, a quick ``15 minutes'' talk to catch up
\item \ldots{} possible deliverable for later on: a NIST talk?
\end{itemize}
\end{enumerate}

\subsubsection{{\bfseries\sffamily TODO} Figure out subtasks to deliver for EmacsConf\hfill{}\textsc{joe:ray:cameron}}
\label{sec:org072efce}
\subsubsection{{\bfseries\sffamily TODO} Figure out how EHN relates to other projects\hfill{}\textsc{joe:ray:cameron}}
\label{sec:orgefbfabe}
\subsubsection{{\bfseries\sffamily TODO} Keep testing crdt.el and lockstep.el\hfill{}\textsc{joe:ray}}
\label{sec:org45fde11}
\subsubsection{{\bfseries\sffamily TODO} Could Emacsconf talk become a blog post?\hfill{}\textsc{joe:ray:cameron}}
\label{sec:orgc4c9b2c}

(Notice that with crdt, typing can go on inside folded nodes! Qiantan
is thinking about a mode to make overlays shareable, which would
change things a bit.)

\subsubsection{Partial prototypes}
\label{sec:orgd85fac0}

How far can we go\ldots{} Through \href{https://roamresearch.com/}{Roam}? (We could at least talk to Connor
about Roam on Twitter?) Through \href{https://jupyter.org/}{Jupyter}? \href{https://foambubble.github.io/foam/}{Foam}? \href{https://gtoolkit.com/}{Glamorous Toolkit}?  Can
we integrate what we’re building with existing tools like these?  Do
Lenses or other kinds of ACT machinery help with this at all?  Would
our system potentially play a role as a universal backend?

\subsubsection{Feature: Arxana 2020}
\label{sec:org9a24dda}

Revisit \href{https://repo.or.cz/w/arxana.git}{Arxana} and turn it into something that we can actually use.
This is rather closely related to the use of “knowledge graph”
formulations we’ve been discussing, since Arxana allows us to combine
writing with knowledge representations.  In our last round of work
with Arxana, we left off at the point of integrating logic programming
into the system.

\subsubsection{Links to useful resources}
\label{sec:orgf3ade97}

Technology like this could be used to build simple demos (e.g., Emacs
in the browser, running Org Mode).  We’ve noticed some other related
tools as well, like \href{https://github.com/200ok-ch/organice}{Organice} and \href{https://github.com/tecosaur/codiorg}{CodiOrg} that could provide
alternative interfaces.

\begin{itemize}
\item \href{https://github.com/exp2exp/notebooks}{exp2exp/notebooks: This is a Docker configuration for running jupyter with multiple kernels on Arch Linux.}
\item \href{https://www.gnu.org/software/emacs/manual/html\_node/emacs/emacsclient-Options.html}{emacsclient Options - GNU Emacs Manual}
\item \href{https://github.com/butlerx/wetty}{butlerx/wetty: Terminal in browser over http/https. (Ajaxterm/Anyterm alternative, but much better)}
\item \href{https://github.com/xtermjs/xterm.js\#real-world-uses}{xtermjs/xterm.js: A terminal for the web}
\item \url{https://twitter.com/cianbutlerx}
\item \href{https://github.com/tsl0922/ttyd}{tsl0922/ttyd: Share your terminal over the web}
\item \href{https://github.com/yudai/gotty}{yudai/gotty: Share your terminal as a web application}
\item \href{https://hub.docker.com/r/butlerx/wetty}{butlerx/wetty - Docker Hub}
\item \href{https://medium.com/@pacroy/setup-web-terminal-using-wetty-docker-image-dcb1ea75bfaf}{Setup Web Terminal using Wetty Docker Image | by Chairat Onyaem (Par) | Medium}
\item \href{https://hub.docker.com/r/krishnasrinivas/wetty/}{krishnasrinivas/wetty - Docker Hub}
\end{itemize}

\subsubsection{Other related work}
\label{sec:org930b572}

\begin{itemize}
\item James Fairbanks (relate this to Betancourt).
\end{itemize}

\subsubsection{Testing}
\label{sec:org5f2590a}

\begin{verbatim}
(def a 2)
\end{verbatim}

\begin{verbatim}
#'user/a
\end{verbatim}

\begin{verbatim}
a
\end{verbatim}

\begin{verbatim}
2
\end{verbatim}

\begin{verbatim}
(range 10)
(def a 1)
\end{verbatim}

\begin{verbatim}
| (0 1 2 3 4 5 6 7 8 9) |
| #'user/a              |
\end{verbatim}

\begin{verbatim}
a
\end{verbatim}

\begin{verbatim}
1
\end{verbatim}

\subsubsection{What would we actually want as our org interface?}
\label{sec:org775f1cf}

Configuration of the \texttt{src} block might look like:

\texttt{maxima :process :backend maxima :results output org}

\begin{itemize}
\item \texttt{:process} stands in for \texttt{:session} now as an alternative
\item \texttt{org-babel-execute-src-block} this is what will be called
\item hang into the \texttt{lang} parameter of the above function, but override using \texttt{:process}
\end{itemize}

\begin{verbatim}
100*9
\end{verbatim}

\begin{verbatim}
| value | 900 |
\end{verbatim}

We had a short problem with this:

\begin{verbatim}
1+1;
(error "No such language mode: nil-mode")
...
\end{verbatim}

\subsubsection{Backends}
\label{sec:org775a2a7}
\begin{enumerate}
\item jupyter
\label{sec:orgc6a2df8}
The jupyter backend works well locally but suffers from a bug when run via tramp. See \hyperref[sec:orgfe96b68]{emacs-jupyter remote debugging}

\item ob-streams
\label{sec:orgd7ae202}

This is work in progress, with some sample content above.
\end{enumerate}

\subsubsection{Future work}
\label{sec:org814c641}

\begin{itemize}
\item Extending to VS Code?  Would people who use VS code even want this kind of interaction?  Maybe VS Code is better for quick visualisations?
\end{itemize}
\subsection{emacs-jupyter remote debugging}
\label{sec:orgfe96b68}
\subsubsection{Set up container on gcp}
\label{sec:org4518fbf}
\begin{enumerate}
\item gcp configuration
\label{sec:org0d7e7e6}

You may like to run \texttt{gcloud auth login} ( \href{https://cloud.google.com/sdk/gcloud/reference/auth/login}{auth login docs} ). This is an interactive process that launches oauth for your google account in the web browser so I think it is best to do it from a terminal though it may be possible to run it in org-babel.

\begin{verbatim}
gcloud config configurations list
\end{verbatim}

\begin{verbatim}
gcloud config configurations describe quarere
\end{verbatim}

\begin{verbatim}
is_active: true
name: quarere
properties:
  compute:
    region: us-central1
    zone: us-central1-f
  core:
    account: camrn86@gmail.com
    project: quarere
\end{verbatim}

\item launch container image
\label{sec:org9914a73}

Deploy a vm based on the container \texttt{cameronraysmith/notebooks:latest}.

\begin{verbatim}
gcloud compute instances create-with-container notebooks-vm \
    --container-image registry.hub.docker.com/cameronraysmith/notebooks:latest \
    --container-restart-policy on-failure \
    --container-privileged \
    --container-stdin \
    --container-tty \
    --container-mount-host-path mount-path=/home/jupyter,host-path=/tmp,mode=rw \
    --machine-type n1-standard-1 \
    --boot-disk-size 50GB \
    --preemptible
\end{verbatim}

Setup ssh with your new instance

\begin{verbatim}
gcloud compute config-ssh
cat ~/.ssh/config | grep "Host notebooks"
\end{verbatim}

\begin{verbatim}
You should now be able to use ssh/scp with your instances.
For example, try running:
ssh notebooks-vm.us-central1-f.quarere
Host notebooks-vm.us-central1-f.quarere
\end{verbatim}


You can \texttt{ssh} into the host machine or the container using the various commands below.

\begin{verbatim}
gcloud compute ssh notebooks-vm # into host machine
ssh notebooks-vm.us-central1-f.quarere docker ps -aqf "name=klt-notebooks-vm-cjme" # check the container ID
gcloud compute ssh notebooks-vm --container klt-notebooks-vm-cjme # use gcloud ssh with --dry-run to print the command
ssh -t notebooks-vm.us-central1-f.quarere -- sudo docker exec -it klt-notebooks-vm-cjme /bin/sh # this takes you directly into the container
\end{verbatim}

Of course you can stop and start the machine with

\begin{verbatim}
gcloud compute instances stop notebooks-vm
gcloud compute instances start notebooks-vm
\end{verbatim}
\end{enumerate}

\subsubsection{Startup the cloud vm running our container of interest}
\label{sec:org9f3eacd}
\begin{enumerate}
\item Setup remote container host machine
\label{sec:org1584082}

We already setup the container named \texttt{notebooks-vm} so all we need to do to begin with is to start it up.

\begin{verbatim}
gcloud compute instances start notebooks-vm
\end{verbatim}

Check that our instance is indeed running

\begin{verbatim}
gcloud compute instances list
\end{verbatim}

\begin{verbatim}
NAME          ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP   STATUS
notebooks     us-central1-c  n1-standard-1               10.128.0.22                TERMINATED
notebooks-vm  us-central1-f  n1-standard-1  true         10.128.0.26  35.223.72.41  RUNNING
\end{verbatim}


Make sure the correct ip address is entered into our \texttt{.ssh/config} file.
\begin{verbatim}
gcloud compute config-ssh
\end{verbatim}

\begin{verbatim}
You should now be able to use ssh/scp with your instances.
For example, try running:

  $ ssh notebooks-vm.us-central1-f.quarere

\end{verbatim}


Inspect the IP address we find in our \texttt{.ssh/config} file

\begin{verbatim}
grep HostName ~/.ssh/config
\end{verbatim}

\begin{verbatim}
HostName 35.224.59.240
HostName 35.223.72.41
\end{verbatim}

\begin{enumerate}
\item Execute commands on the remote container host machine
\label{sec:orge27e44e}
\begin{verbatim}
hostname --long
\end{verbatim}

\begin{verbatim}

$ notebooks-vm.us-central1-f.c.quarere.internal
\end{verbatim}


\begin{verbatim}
docker container ls
\end{verbatim}

\begin{verbatim}
CONTAINER ID        IMAGE                                                                COMMAND                  CREATED              STATUS              PORTS               NAMES
7e5e8974adc8        registry.hub.docker.com/cameronraysmith/notebooks:latest             "/bin/sh -c 'jupyter…"   About a minute ago   Up About a minute                       klt-notebooks-vm-cjme
5a480b60af52        gcr.io/stackdriver-agents/stackdriver-logging-agent:0.2-1.5.33-1-1   "/entrypoint.sh /usr…"   About a minute ago   Up About a minute                       stackdriver-logging-agent
\end{verbatim}


\begin{verbatim}
docker container ls
\end{verbatim}

\begin{verbatim}

$ CONTAINER ID        IMAGE                              COMMAND                  CREATED             STATUS              PORTS                      NAMES
caadc9a126bb        gcr.io/inverting-proxy/agent       "/bin/sh -c '/opt/bi…"   2 hours ago         Up 2 hours                                     proxy-agent
8080/tcp   payload-container
\end{verbatim}
\end{enumerate}
\end{enumerate}

\subsubsection{Run shell commands on the remote container}
\label{sec:orga189ad0}
To switch between two available configurations, choose one of the lines below to copy to the \texttt{:PROPERTIES:} drawer for this section.
\begin{verbatim}
:header-args: :results output verbatim replace :session notebookscontainer :dir /ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:  :exports both  :eval never-export
:header-args: :results output verbatim replace :session notebookscontainer :dir /ssh:notebooks.us-central1-c.quarere|docker:payload-container:  :exports both  :eval never-export
\end{verbatim}

In order to connect to the remote host followed by the docker container we specify the directory as \texttt{ssh:notebooks-vm} (including the extra details we got from \texttt{gcloud compute ssh-config}) followed by \texttt{docker:containername} where we got the container name from running \texttt{docker container ls} on the remote machine.

\begin{verbatim}
echo $JUPYTER_PATH
\end{verbatim}

\begin{verbatim}

$
\end{verbatim}


\begin{verbatim}
head -3 /proc/self/cgroup
\end{verbatim}

\begin{verbatim}

$ 12:blkio:/docker/0313f41d52ad7945b5f9687efc0d1e3431e531eb7a29c8d7eecf5fddcbef0f93
11:net_cls,net_prio:/docker/0313f41d52ad7945b5f9687efc0d1e3431e531eb7a29c8d7eecf5fddcbef0f93
10:hugetlb:/docker/0313f41d52ad7945b5f9687efc0d1e3431e531eb7a29c8d7eecf5fddcbef0f93
\end{verbatim}


Check the working directory and the list of jupyter kernels
\begin{verbatim}
(push "-e" docker-tramp-docker-options)
(push "-e" "JUPYTER_PATH=/home/jovyan/.local/share/jupyter:/usr/local/share/jupyter:/usr/share/jupyter" docker-tramp-docker-options)
\end{verbatim}

\begin{verbatim}
echo $JUPYTER_PATH
\end{verbatim}

\begin{verbatim}
jupyter kernelspec list
\end{verbatim}

\begin{verbatim}
Available kernels:
  ir           /home/jovyan/.local/share/jupyter/kernels/ir
  julia-1.5    /home/jovyan/.local/share/jupyter/kernels/julia-1.5
  maxima       /home/jovyan/.local/share/jupyter/kernels/maxima
  python3      /usr/share/jupyter/kernels/python3
\end{verbatim}


If you try to make use of an existing session on the docker container to run one of the \texttt{emacs-jupyter} kernels, you find that there is a different usage of the TRAMP remote path specification in the \texttt{:dir} property for the \texttt{sh} language of babel and with the \texttt{:session} property in the \texttt{emacs-jupyter} \emph{language} of babel. This is the error I got the first time I tried this with the TRAMP remote path specification in \texttt{:dir}:

\begin{verbatim}
: FileNotFoundErrorTraceback (most recent call last)
: <ipython-input-1-d4b8d99aef95> in <module>
:       1 import os
:       2 __JUPY_saved_dir = os.getcwd()
: ----> 3 os.chdir("/ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:/home/jovyan/")
:       4 try:
:       5     get_ipython().run_cell("""x = 'foo'
:
: FileNotFoundError: [Errno 2] No such file or directory: '/ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:/home/jovyan/'
\end{verbatim}

\begin{enumerate}
\item Run python session on the remote container
\label{sec:org674421e}
The default properties that should apply to this section are

\begin{verbatim}
:header-args: :results output verbatim replace :session notebookscontainer-python :dir /ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:/home/jovyan/  :exports both  :eval never-export
\end{verbatim}

In order to connect to the remote host followed by the docker container we specify the directory as \texttt{ssh:notebooks-vm} (including the extra details we got from \texttt{gcloud compute ssh-config}) followed by a \texttt{|} and then \texttt{docker:containername} where we got the container name from running \texttt{docker container ls} on the remote machine.

\begin{verbatim}
x = 'foo'
y = 'bar'
print(x + ' ' + y)
\end{verbatim}

\begin{verbatim}
foo bar
\end{verbatim}


\begin{verbatim}
x = 1 + 1
print(x)
\end{verbatim}

\begin{verbatim}
2
\end{verbatim}
\end{enumerate}

\subsubsection{BUG: Run a jupyter kernel in a remote container}
\label{sec:org6df1280}
\begin{enumerate}
\item properties
\label{sec:orgce300b2}
To switch between two available configurations, choose one of the lines below to copy to the \texttt{:PROPERTIES:} drawer for this section.
\begin{verbatim}
:header-args: :results output verbatim replace :session /ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:notebooks01  :exports both  :eval never-export
:header-args: :results output verbatim replace :session /ssh:notebooks.us-central1-c.quarere|docker:payload-container:notebooks01  :exports both  :eval never-export
\end{verbatim}

\item test code
\label{sec:org166d43b}

\begin{verbatim}
x = 'foo'
y = 'bar'
x + ' ' + y
\end{verbatim}

There is a problem whereby the \texttt{:dir} property is being passed along to jupyter as if it were a file. It looks like the intention may be to pass the TRAMP parameters to \texttt{:session} rather than \texttt{:dir} in the case of \texttt{emacs-jupyter}.

Here there is a bug that has been reported in \href{https://github.com/nnicandro/emacs-jupyter/issues/191}{issue 191 of emacs-jupyter}.

\begin{verbatim}
executing Jupyter-Python code block...
jupyter-start-kernel: default-directory = /ssh:cloudmachine|docker:containeroncloudmachine:
jupyter-start-kernel: Starting process with args "/bin/python3 -c from jupyter_client.kernelapp import main; main() --kernel=python3"
Tramp: Opening connection for containeroncloudmachine using docker...
Tramp: Sending command ‘exec ssh -q    -e none cloudmachine’
Tramp: Waiting for prompts from remote shell...done
Tramp: Found remote shell prompt on ‘cloudmachine’
Tramp: Sending command ‘exec docker  exec -it  containeroncloudmachine sh’
Tramp: Waiting for prompts from remote shell...done
Tramp: Found remote shell prompt on ‘containeroncloudmachine’
Tramp: Opening connection for containeroncloudmachine using docker...done
Launching python3 kernel process...done
Tramp: Inserting ‘/ssh:cloudmachine|docker:containeroncloudmachine:/home/jovyan/.local/share/jupyter/runtime/kernel-fc5b0ea7-f553-4725-aa59-32829d356665.json’...
Tramp: Encoding remote file ‘/ssh:cloudmachine|docker:containeroncloudmachine:/home/jovyan/.local/share/jupyter/runtime/kernel-fc5b0ea7-f553-4725-aa59-32829d356665.json’ with ‘base64 <%s’...done
Tramp: Decoding local file ‘/var/folders/1d/wtzfcz5s4x98nbkdx9g5ss3c0000gn/T/tramp.krOJmR.json’ with ‘base64-decode-region’...done
Tramp: Inserting ‘/ssh:cloudmachine|docker:containeroncloudmachine:/home/jovyan/.local/share/jupyter/runtime/kernel-fc5b0ea7-f553-4725-aa59-32829d356665.json’...done
SENDING: :kernel-info-request ae928b51-f755-441e-a250-8a08c58d734d nil
SENT: (:shell ae928b51-f755-441e-a250-8a08c58d734d)
Requesting kernel info...done
jupyter-kernel-info: Kernel did not respond to kernel-info request
\end{verbatim}

There is a \href{https://github.com/nnicandro/emacs-jupyter/issues/72\#issuecomment-543952258}{suggestion from arthurcgusmao} in another issue stating one needs to set the \texttt{JUPYTER\_PATH} environment variable to resolve the \texttt{Kernel did not respond to kernel-info request} issue.

It is simple to set the \texttt{JUPYTER\_PATH} environment variable via tramp

\begin{verbatim}
(add-to-list 'tramp-remote-process-environment "JUPYTER_PATH=/home/jovyan/.local/share/jupyter:/usr/local/share/jupyter:/usr/share/jupyter")
\end{verbatim}

however, this does not resolve the issue.

I originally tried to set the environment variable by passing a parameter to docker, but this did not work properly in the sense that if you check the value from inside the container it does not appear to be set despite what appears to be the appropriate docker flag for doing so.

\begin{verbatim}
(push "-e" "JUPYTER_PATH=/home/jovyan/.local/share/jupyter:/usr/local/share/jupyter:/usr/share/jupyter" docker-tramp-docker-options)
(setq docker-tramp-docker-options
      '("-e" "JUPYTER_PATH=/home/jovyan/.local/share/jupyter:/usr/local/share/jupyter:/usr/share/jupyter"))
\end{verbatim}

\item Debugging \texttt{jupyter-kernel-info}
\label{sec:org8fe93d0}

\texttt{jupyter-kernel-info} is the function from which the error \texttt{Kernel did not respond to kernel-info request} arises (see \href{https://github.com/nnicandro/emacs-jupyter/blob/403c70c83cb3754c83da0932b0efaf5e72bdca9a/jupyter-client.el\#L2066}{line 2066 of jupyter-client.el}).

The stack trace for \texttt{jupyter-kernel-info}

\begin{verbatim}
Debugger entered--entering a function:
jupyter-kernel-info(#<jupyter-org-client jupyter-org-client-1fe73d7aa114>)
jupyter--error-if-no-kernel-info(#<jupyter-org-client jupyter-org-client-1fe73d7aa114>)
jupyter-start-new-kernel("julia-1.5" jupyter-org-client)
jupyter-run-repl("julia-1.5" nil nil jupyter-org-client)
#f(compiled-function (session kernel) "Initiate a client connected to a remote kernel process." #<bytecode 0x1fe7435018f5>)(#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
apply(#f(compiled-function (session kernel) "Initiate a client connected to a remote kernel process." #<bytecode 0x1fe7435018f5>) (#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5"))
#f(compiled-function (&rest args) #<bytecode 0x1fe743520a15>)(#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
apply(#f(compiled-function (&rest args) #<bytecode 0x1fe743520a15>) (#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5"))
#f(compiled-function (&rest cnm-args) #<bytecode 0x1fe7430d03fd>)()
#f(compiled-function (cl--cnm session kernel) "Rename the returned client's REPL buffer to include SESSION's name.\nAlso set `jupyter-include-other-output' to nil for the session so\nthat output produced by other clients do not get handled by the\nclient." #<bytecode 0x1fe7434f577d>)(#f(compiled-function (&rest cnm-args) #<bytecode 0x1fe7430d03fd>) #s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
apply(#f(compiled-function (cl--cnm session kernel) "Rename the returned client's REPL buffer to include SESSION's name.\nAlso set `jupyter-include-other-output' to nil for the session so\nthat output produced by other clients do not get handled by the\nclient." #<bytecode 0x1fe7434f577d>) #f(compiled-function (&rest cnm-args) #<bytecode 0x1fe7430d03fd>) (#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5"))
#f(compiled-function (&rest args) #<bytecode 0x1fe743520a41>)(#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
apply(#f(compiled-function (&rest args) #<bytecode 0x1fe743520a41>) #s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
org-babel-jupyter-initiate-client(#s(org-babel-jupyter-remote-session :name "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." :connect-repl-p nil) "julia-1.5")
org-babel-jupyter-initiate-session-by-key("/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." ((:colname-names) (:rowname-names) (:result-params "replace") (:result-type . value) (:results . "replace") (:exports . "both") (:cache . "no") (:noweb . "no") (:hlines . "no") (:tangle . "no") (:eval . "never-export") (:async . "no") (:session . "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt...") (:kernel . "julia-1.5")))
#f(compiled-function (&optional session params) "Initialize a Jupyter SESSION according to PARAMS." #<bytecode 0x1fe7439bd0c1>)("/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." ((:colname-names) (:rowname-names) (:result-params "replace") (:result-type . value) (:results . "replace") (:exports . "both") (:cache . "no") (:noweb . "no") (:hlines . "no") (:tangle . "no") (:eval . "never-export") (:async . "no") (:session . "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt...") (:kernel . "julia-1.5")))
apply(#f(compiled-function (&optional session params) "Initialize a Jupyter SESSION according to PARAMS." #<bytecode 0x1fe7439bd0c1>) ("/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." ((:colname-names) (:rowname-names) (:result-params "replace") (:result-type . value) (:results . "replace") (:exports . "both") (:cache . "no") (:noweb . "no") (:hlines . "no") (:tangle . "no") (:eval . "never-export") (:async . "no") (:session . "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt...") (:kernel . "julia-1.5"))))
org-babel-jupyter-initiate-session("/ssh:notebooks-vm.us-central1-f.quarere|docker:klt..." ((:colname-names) (:rowname-names) (:result-params "replace") (:result-type . value) (:results . "replace") (:exports . "both") (:cache . "no") (:noweb . "no") (:hlines . "no") (:tangle . "no") (:eval . "never-export") (:async . "no") (:session . "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt...") (:kernel . "julia-1.5")))
org-babel-execute:jupyter-julia("x = \"foo\"\ny = \"bar\"\nprintln(x)\nprintln(y)" ((:colname-names) (:rowname-names) (:result-params "replace") (:result-type . value) (:results . "replace") (:exports . "both") (:cache . "no") (:noweb . "no") (:hlines . "no") (:tangle . "no") (:eval . "never-export") (:async . "no") (:session . "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt...") (:kernel . "julia-1.5")))
#f(compiled-function (&optional arg info params) "Execute the current source code block.\nInsert the results of execution into the buffer.  Source code\nexecution and the collection and formatting of results can be\ncontrolled through a variety of header arguments.\n\nWith prefix argument ARG, force re-execution even if an existing\nresult cached in the buffer would otherwise have been returned.\n\nOptionally supply a value for INFO in the form returned by\n`org-babel-get-src-block-info'.\n\nOptionally supply a value for PARAMS which will be merged with\nthe header arguments specified at the front of the source code\nblock." (interactive nil) #<bytecode 0x1fe742a390dd>)(nil nil nil)
ob-async-org-babel-execute-src-block(#f(compiled-function (&optional arg info params) "Execute the current source code block.\nInsert the results of execution into the buffer.  Source code\nexecution and the collection and formatting of results can be\ncontrolled through a variety of header arguments.\n\nWith prefix argument ARG, force re-execution even if an existing\nresult cached in the buffer would otherwise have been returned.\n\nOptionally supply a value for INFO in the form returned by\n`org-babel-get-src-block-info'.\n\nOptionally supply a value for PARAMS which will be merged with\nthe header arguments specified at the front of the source code\nblock." (interactive nil) #<bytecode 0x1fe742a390dd>) nil)
apply(ob-async-org-babel-execute-src-block #f(compiled-function (&optional arg info params) "Execute the current source code block.\nInsert the results of execution into the buffer.  Source code\nexecution and the collection and formatting of results can be\ncontrolled through a variety of header arguments.\n\nWith prefix argument ARG, force re-execution even if an existing\nresult cached in the buffer would otherwise have been returned.\n\nOptionally supply a value for INFO in the form returned by\n`org-babel-get-src-block-info'.\n\nOptionally supply a value for PARAMS which will be merged with\nthe header arguments specified at the front of the source code\nblock." (interactive nil) #<bytecode 0x1fe742a390dd>) nil)
org-babel-execute-src-block(nil)
(cond ((eq type 'headline) (cond ((memq (and (boundp 'org-goto-map) org-goto-map) (current-active-maps)) (org-goto-ret)) ((and (fboundp 'toc-org-insert-toc) (member "TOC" (org-get-tags))) (toc-org-insert-toc) (message "Updating table of contents")) ((string= "ARCHIVE" (car-safe (org-get-tags))) (org-force-cycle-archived)) ((or (org-element-property :todo-type context) (org-element-property :scheduled context)) (org-todo (if (eq (org-element-property :todo-type context) 'done) (or (car ...) 'todo) 'done)))) (org-update-checkbox-count) (org-update-parent-todo-statistics) (if (and (fboundp 'toc-org-insert-toc) (member "TOC" (org-get-tags))) (progn (toc-org-insert-toc) (message "Updating table of contents"))) (let* ((beg (if (org-before-first-heading-p) (line-beginning-position) (save-excursion (org-back-to-heading) (point)))) (end (if (org-before-first-heading-p) (line-end-position) (save-excursion (org-end-of-subtree) (point)))) (overlays (condition-case nil (progn (overlays-in beg end)) (error nil))) (latex-overlays (cl-find-if #'(lambda ... ...) overlays)) (image-overlays (cl-find-if #'(lambda ... ...) overlays))) (+org--toggle-inline-images-in-subtree beg end) (if (or image-overlays latex-overlays) (org-clear-latex-preview beg end) (org--latex-preview-region beg end)))) ((eq type 'clock) (org-clock-update-time-maybe)) ((eq type 'footnote-reference) (org-footnote-goto-definition (org-element-property :label context))) ((eq type 'footnote-definition) (org-footnote-goto-previous-reference (org-element-property :label context))) ((memq type '(timestamp planning)) (org-follow-timestamp-link)) ((memq type '(table-row table)) (if (org-at-TBLFM-p) (org-table-calc-current-TBLFM) (condition-case nil (progn (save-excursion (goto-char (org-element-property :contents-begin context)) (org-call-with-arg 'org-table-recalculate (or arg t)))) (error nil)))) ((eq type 'table-cell) (org-table-blank-field) (org-table-recalculate arg) (if (and (string-empty-p (string-trim (org-table-get-field))) (and (boundp 'evil-local-mode) evil-local-mode)) (progn (evil-change-state 'insert)))) ((eq type 'babel-call) (org-babel-lob-execute-maybe)) ((eq type 'statistics-cookie) (save-excursion (org-update-statistics-cookies arg))) ((memq type '(inline-src-block src-block)) (org-babel-execute-src-block arg)) ((memq type '(latex-environment latex-fragment)) (org-latex-preview arg)) ((eq type 'link) (let* ((lineage (org-element-lineage context '(link) t)) (path (org-element-property :path lineage))) (if (or (equal (org-element-property :type lineage) "img") (and path (image-type-from-file-name path))) (+org--toggle-inline-images-in-subtree (org-element-property :begin lineage) (org-element-property :end lineage)) (org-open-at-point arg)))) ((org-element-property :checkbox (org-element-lineage context '(item) t)) (let ((match (and (org-at-item-checkbox-p) (match-string 1)))) (org-toggle-checkbox (if (equal match "[ ]") '(16))))) (t (if (or (org-in-regexp org-ts-regexp-both nil t) (org-in-regexp org-tsr-regexp-both nil t) (org-in-regexp org-link-any-re nil t)) (call-interactively #'org-open-at-point) (+org--toggle-inline-images-in-subtree (org-element-property :begin context) (org-element-property :end context)))))
(let* ((context (org-element-context)) (type (org-element-type context))) (while (and context (memq type '(verbatim code bold italic underline strike-through subscript superscript))) (setq context (org-element-property :parent context) type (org-element-type context))) (cond ((eq type 'headline) (cond ((memq (and (boundp ...) org-goto-map) (current-active-maps)) (org-goto-ret)) ((and (fboundp 'toc-org-insert-toc) (member "TOC" (org-get-tags))) (toc-org-insert-toc) (message "Updating table of contents")) ((string= "ARCHIVE" (car-safe (org-get-tags))) (org-force-cycle-archived)) ((or (org-element-property :todo-type context) (org-element-property :scheduled context)) (org-todo (if (eq ... ...) (or ... ...) 'done)))) (org-update-checkbox-count) (org-update-parent-todo-statistics) (if (and (fboundp 'toc-org-insert-toc) (member "TOC" (org-get-tags))) (progn (toc-org-insert-toc) (message "Updating table of contents"))) (let* ((beg (if (org-before-first-heading-p) (line-beginning-position) (save-excursion ... ...))) (end (if (org-before-first-heading-p) (line-end-position) (save-excursion ... ...))) (overlays (condition-case nil (progn ...) (error nil))) (latex-overlays (cl-find-if #'... overlays)) (image-overlays (cl-find-if #'... overlays))) (+org--toggle-inline-images-in-subtree beg end) (if (or image-overlays latex-overlays) (org-clear-latex-preview beg end) (org--latex-preview-region beg end)))) ((eq type 'clock) (org-clock-update-time-maybe)) ((eq type 'footnote-reference) (org-footnote-goto-definition (org-element-property :label context))) ((eq type 'footnote-definition) (org-footnote-goto-previous-reference (org-element-property :label context))) ((memq type '(timestamp planning)) (org-follow-timestamp-link)) ((memq type '(table-row table)) (if (org-at-TBLFM-p) (org-table-calc-current-TBLFM) (condition-case nil (progn (save-excursion (goto-char ...) (org-call-with-arg ... ...))) (error nil)))) ((eq type 'table-cell) (org-table-blank-field) (org-table-recalculate arg) (if (and (string-empty-p (string-trim (org-table-get-field))) (and (boundp 'evil-local-mode) evil-local-mode)) (progn (evil-change-state 'insert)))) ((eq type 'babel-call) (org-babel-lob-execute-maybe)) ((eq type 'statistics-cookie) (save-excursion (org-update-statistics-cookies arg))) ((memq type '(inline-src-block src-block)) (org-babel-execute-src-block arg)) ((memq type '(latex-environment latex-fragment)) (org-latex-preview arg)) ((eq type 'link) (let* ((lineage (org-element-lineage context '... t)) (path (org-element-property :path lineage))) (if (or (equal (org-element-property :type lineage) "img") (and path (image-type-from-file-name path))) (+org--toggle-inline-images-in-subtree (org-element-property :begin lineage) (org-element-property :end lineage)) (org-open-at-point arg)))) ((org-element-property :checkbox (org-element-lineage context '(item) t)) (let ((match (and (org-at-item-checkbox-p) (match-string 1)))) (org-toggle-checkbox (if (equal match "[ ]") '(16))))) (t (if (or (org-in-regexp org-ts-regexp-both nil t) (org-in-regexp org-tsr-regexp-both nil t) (org-in-regexp org-link-any-re nil t)) (call-interactively #'org-open-at-point) (+org--toggle-inline-images-in-subtree (org-element-property :begin context) (org-element-property :end context))))))
\end{verbatim}

Printing the value of the \texttt{client} variable from inside \texttt{edebug} on \texttt{jupyter-kernel-info} yields

\begin{verbatim}
;; client  ;;pp-eval-last-sexp
#s(jupyter-org-client
   (#<finalizer>)
   jupyter--clients "idle" 1 #s(hash-table size 65 test equal rehash-size 1.5 rehash-threshold 0.8125 data
                                           ())
   nil #s(jupyter-channel-ioloop-comm
          (#s(hash-table size 1 test eql weakness value rehash-size 1.5 rehash-threshold 0.8125 data
                         (t #0)))
          #s(jupyter-zmq-channel-ioloop
             (#<finalizer>)
             #<process zmq> nil
             ((send
               ((channel jupyter-channel)
                msg-type msg msg-id)
               ((list 'sent
                      (oref channel type)
                      (jupyter-send channel msg-type msg msg-id))))
              (stop-channel
               (type)
               ((let
                    ((channel
                      (object-assoc type :type jupyter-channel-ioloop-channels)))
                  (when
                      (and channel
                           (jupyter-channel-alive-p channel))
                    (jupyter-stop-channel channel))
                  (list 'stop-channel type))))
              (start-channel
               ((channel jupyter-channel)
                endpoint)
               ((when
                    (jupyter-channel-alive-p channel)
                  (jupyter-stop-channel channel))
                (oset channel endpoint endpoint)
                (let
                    ((identity
                      (jupyter-session-id jupyter-channel-ioloop-session)))
                  (jupyter-start-channel channel :identity identity))
                (list 'start-channel
                      (oref channel type)))))
             ((setq jupyter-channel-ioloop-session
                    (jupyter-session :id "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7"))
              (require 'jupyter-channel-ioloop)
              (require 'jupyter-zmq-channel-ioloop)
              (push 'jupyter-zmq-channel-ioloop--recv-messages jupyter-ioloop-post-hook)
              (cl-loop for channel in
                       '(:shell :stdin :iopub)
                       unless
                       (object-assoc channel :type jupyter-channel-ioloop-channels)
                       do
                       (push
                        (jupyter-zmq-channel :session jupyter-channel-ioloop-session :type channel)
                        jupyter-channel-ioloop-channels)))
             ((mapc #'jupyter-stop-channel jupyter-channel-ioloop-channels)))
          #s(jupyter-hb-channel :hb #s(jupyter-session
                                       (:shell_port 60543 :iopub_port 52071 :stdin_port 46591 :control_port 37599 :hb_port 49243 :ip "127.0.0.1" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7" :transport "tcp" :signature_scheme "hmac-sha256" :kernel_name "julia-1.5")
                                       "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" "a1369b21-aa7ff7834dd1f3fa5f7108e7")
                                "tcp://127.0.0.1:49243" #<user-ptr ptr=0x6000002f88a0 finalizer=0x10e782ed0> 10 ignore t t)
          jupyter-zmq-channel-ioloop #s(jupyter-session
                                        (:shell_port 60543 :iopub_port 52071 :stdin_port 46591 :control_port 37599 :hb_port 49243 :ip "127.0.0.1" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7" :transport "tcp" :signature_scheme "hmac-sha256" :kernel_name "julia-1.5")
                                        "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" "a1369b21-aa7ff7834dd1f3fa5f7108e7")
          (:stdin #s(jupyter-proxy-channel "tcp://127.0.0.1:46591" t)
                  :shell #s(jupyter-proxy-channel "tcp://127.0.0.1:60543" t)
                  :iopub #s(jupyter-proxy-channel "tcp://127.0.0.1:52071" t)))
   #s(jupyter-session
      (:shell_port 60543 :iopub_port 52071 :stdin_port 46591 :control_port 37599 :hb_port 49243 :ip "127.0.0.1" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7" :transport "tcp" :signature_scheme "hmac-sha256" :kernel_name "julia-1.5")
      "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" "a1369b21-aa7ff7834dd1f3fa5f7108e7")
   #s(hash-table size 65 test equal rehash-size 1.5 rehash-threshold 0.8125 data
                 ())
   #s(jupyter-kernel-process-manager
      (#<finalizer>)
      jupyter--kernel-managers #s(jupyter-command-kernel
                                  (#<finalizer>)
                                  ("julia-1.5" "/ssh:notebooks-vm.us-central1-f.quarere|docker:klt-notebooks-vm-cjme:/home/jovyan/.local/share/jupyter/kernels/julia-1.5" :argv
                                   ["/usr/bin/julia" "-i" "--startup-file=yes" "--color=yes" "--project=@." "/home/jovyan/.julia/packages/IJulia/tOM8L/src/kernel.jl" "{connection_file}"]
                                   :env nil :display_name "Julia 1.5.1" :language "julia" :interrupt_mode "signal" :metadata nil)
                                  #s(jupyter-session
                                     (:shell_port 60543 :iopub_port 52071 :stdin_port 46591 :control_port 37599 :hb_port 49243 :ip "127.0.0.1" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7" :transport "tcp" :signature_scheme "hmac-sha256" :kernel_name "julia-1.5")
                                     "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" "a1369b21-aa7ff7834dd1f3fa5f7108e7")
                                  #<process jupyter-kernel-julia-1.5>)
      #s(jupyter-zmq-channel :control #s(jupyter-session
                                         (:shell_port 60543 :iopub_port 52071 :stdin_port 46591 :control_port 37599 :hb_port 49243 :ip "127.0.0.1" :key "a1369b21-aa7ff7834dd1f3fa5f7108e7" :transport "tcp" :signature_scheme "hmac-sha256" :kernel_name "julia-1.5")
                                         "38bcac68-f74f-4bd2-b1e7-998df7c14c4f" "a1369b21-aa7ff7834dd1f3fa5f7108e7")
                             "tcp://127.0.0.1:37599" #<user-ptr ptr=0x6000002f8900 finalizer=0x10e782ed0>))
   #<buffer  *jupyter-kernel-client*> nil "null" nil nil nil)
\end{verbatim}

When I check all of the existing kernel files, I find one whose kernel ID is different ( \texttt{14238987-f1b4-4049-982a-94012ddb7087} )from what is contained in the \texttt{client} variable ( \texttt{38bcac68-f74f-4bd2-b1e7-998df7c14c4f} ), but whose key and various ports are all correct.

\begin{verbatim}
/docker:klt-notebooks-vm-cjme:/home/jovyan/ #$ cat .local/share/jupyter/runtime/kernel-14238987-f1b4-4049-982a-94012ddb7087.json
{
  "shell_port": 60543,
  "iopub_port": 52071,
  "stdin_port": 46591,
  "control_port": 37599,
  "hb_port": 49243,
  "ip": "127.0.0.1",
  "key": "a1369b21-aa7ff7834dd1f3fa5f7108e7",
  "transport": "tcp",
  "signature_scheme": "hmac-sha256",
  "kernel_name": "julia-1.5"
}
\end{verbatim}

This suggests that the root of the problem is that the kernel ID is not being captured accurately. There is no kernel with an ID equivalent to the one that appears in the \texttt{client} variable, so it is not clear to me where the value that appears in the client variable is coming from. I don't know if there is any condition in which jupyter changes the kernel ID and leaves all other parameters the same.

The issue appears to arise in \texttt{jupyter-make-client} (see \href{https://github.com/nnicandro/emacs-jupyter/blob/a9ae0bcef52a62cf7df520756d994162a0570156/jupyter-kernel-manager.el\#L141}{L141 in jupyter-kernel-manager.el}) when calling \texttt{make-instance class} for class \texttt{jupyter-org-client} which derives from \texttt{jupyter-repl-client} which derives from \texttt{jupyter-kernel-client}. The \texttt{session} is defined as an element of \texttt{jupyter-kernel-client} at \href{https://github.com/nnicandro/emacs-jupyter/blob/403c70c83cb3754c83da0932b0efaf5e72bdca9a/jupyter-client.el\#L215}{L215 of jupyter-client.el}.
\end{enumerate}
\section{Which model construction process works as a whole?}
\label{sec:orge4f8634}
We are working in an applied way to build models, starting with data
and using existing tools and methods, but without any strong guarantee
that we will find the most effective methods right away. So, with
these experiments we are investigating the process of “model
construction” generally understood. One example is building
computational structures from natural language and technical texts.

\subsection{Information extraction from SO Q\&A items}
\label{sec:orgb11b61a}
We are attempting to extract triples from textual Q\&A by using a
Neural Machine Translation approach.

\subsubsection{{\bfseries\sffamily BACKBURNER} Refinining OpenIE approach\hfill{}\textsc{deyan}}
\label{sec:org44056fd}
\subsection{Knowledge graph}
\label{sec:org16627c7}
Once we have a model of knowledge from Q\&A items, e.g., in the form of
triples. we will want to be able to do something with this material.
One way in which it may be useful is in combination with an existing
knowledge graph.  For example, we can look at material from Concept
Net.  We may also have to make some of our own Concept Net-like
graphs.

\subsubsection{Practical work}
\label{sec:org5ebfd6f}

We can already take some practical steps here, along the lines of the
earlier papers ``Modelling the way mathematics is actually done'' and
``Towards mathematical AI via a model of the content and process of
mathematical question and answer dialogues''.

\subsubsection{{\bfseries\sffamily STARTED} Analyse a small sample of examples from s.o.\hfill{}\textsc{joe}}
\label{sec:orgd5990b6}
\section{Underlying foundation}
\label{sec:orgb5fcde2}
We believe that category-theoretic foundations will help us make
progress across different representations of code, process, model
building, and so on.

\subsection{Category theoretic glue}
\label{sec:org58a11b3}
We want to develop enough theory that we can use it to frame our
experiments.  We are trying to do this in a computationally meaningful way.

\subsubsection{Feature: Understand comma categories as a potential “backend”\hfill{}\textsc{ray:zans}}
\label{sec:org9394a05}

\subsection{Probabilistic programming for scientific modelling}
\label{sec:org6ef6a83}
Probabilistic programming is useful within both scientific modelling,
and, potentially, as part of a program synthesis toolkit.

\subsubsection{Feature: relationship between probabilistic programming and categories\hfill{}\textsc{zans:cameron}}
\label{sec:orge6ec2c3}
\section{POTENTIAL PRODUCTS}
\label{sec:org119f64b}
Synthesis of some of our \emph{projects} could lead to marketable \emph{products}.

\subsection{Agent model}
\label{sec:orgd46a760}
One of our central intentions is to instantiate our work in an agent
model of Q\&A and programming.  This is based on Alan Turing’s
suggestion that computers could talk with each other to sharpen their
wits.
\subsection{Recommender System}
\label{sec:org72161d9}
We could consume various analyses of Stack Exchange data to make
recommendations.

\subsubsection{Possible implementation strategy: build on a version of GPT fine-tuned on SO Q\&A tasks}
\label{sec:orgc88bf25}

Could we set up a simple version of \textbf{GPT} trained on Stack Overflow
data, just to get it working? Then think about how to get a learning
loop set up to improve the results\ldots{}

\begin{enumerate}
\item Ideas
\label{sec:org158ffde}

\begin{itemize}
\item Could this at least help a human navigate the questions on Stack Exchange?
\item Rather than just answering the question, generate the answer and use
that to guide search (by combining generation with document similarity)
\item Use a distance to set up a margin of tolerance
\end{itemize}

\item Precedents
\label{sec:orgcb2426c}

\begin{itemize}
\item \href{https://stackroboflow.com/about/index.html}{Stack Roboflow} creates ersatz Q\&A using \texttt{AWD\_LTSM}.  Surely we can do better?
\item In Google Books, they use crappy OCR which is good enough for search, but you wouldn't want to read the output.  For search, they use something like rewrite distance, finding something ‘within 5 errors’.
\end{itemize}

\item Analogue
\label{sec:org1c1b842}

In parsing, it's not just edit distance but has to involve the grammar

\item Case against going too deep:
\label{sec:orge278867}

\begin{itemize}
\item Code generation is hard
\end{itemize}

\item Case against worrying about that:
\label{sec:org5c58f44}

\begin{itemize}
\item Worry instead about applications like generating learning packets
\begin{itemize}
\item E.g., learn everything there is to know about \texttt{git} from Stack Overflow in a nicely organised way.
\item E.g., compare the Schuam’s Outline series: could we reassemble open source clones of Schuam’s Outlines by retrieving contents from Math.Stack Exchange?
\end{itemize}
\end{itemize}

\item Application of the model: Display SO with similarity graph
\label{sec:org282ed38}
E.g., use generated answers to help identify ‘similarity’.

\item Related work
\label{sec:org1c8c3ba}

\begin{itemize}
\item \url{https://github.com/stared/tag-graph-map-of-stackexchange/wiki} presents a nice-looking map of the relationship between tags.
\end{itemize}
\end{enumerate}

\subsubsection{Feature: Initial import of SO for training\hfill{}\textsc{tim}}
\label{sec:org40bd709}

\subsection{Visual Interfaces}
\label{sec:org6bee9e8}
\subsubsection{Graphical flow for programs}
\label{sec:org8f86b16}

Can we model more general program flow in a similar fashion to Monocl?

\subsubsection{Limitations}
\label{sec:orgf2aa444}

The idea of graphical programming languages is linked with the
\href{https://en.wikipedia.org/wiki/Deutsch\_limit}{Deutsch limit} (named for noted programmer \href{https://en.wikipedia.org/wiki/L.\_Peter\_Deutsch}{L Peter Deutsch}, not
physicist \href{https://en.wikipedia.org/wiki/David\_Deutsch}{David Deutsch FRS}, though perhaps he could come into play later):

\begin{quote}
\emph{The problem with visual programming is that you can’t have more than 50 visual primitives on the screen at the same time.}
\end{quote}

\subsubsection{Automatically create visual interfaces}
\label{sec:orgc3f45fe}

Here's an idea: assuming we have enough text mining pixie dust (on
corpora of linux man pages, and stack overflow questions/forum posts
about linux commands), it might be possible to do:

\texttt{user:\textasciitilde{}\$ make-gui-for ls -{}-output ls.py}

\subsubsection{Feature: Build infra for generating and displaying graphs.}
\label{sec:orgfecad23}

E.g., we can generate graphs based on code flow.

\begin{verbatim}
(defun triangle (n)
  (if (equal n 0) 0
    (+ n (triangle (- n 1)))))
\end{verbatim}

This would then be related to the visual code walk through feature described below.

\subsubsection{Feature: Visual code walk through}
\label{sec:orgda1a7b3}

Ray is working on a visual code walk through.  This should be seen as
another interface to the same basic underlying information, sort of
like how Org Roam is the main interface to the data served by Org Roam
Server.

\begin{enumerate}
\item General evaluation strategy for these demos:
\label{sec:orgc917354}

\begin{itemize}
\item \emph{‘Would anyone want to use this?’}
\item E.g., in the case of Emacs ``learn X in Y'' demo.
\item If there is interest, work up to covering the HtDP book
\end{itemize}

\item Related work
\label{sec:org3719e1d}

\begin{description}
\item[{MAUDE framework.}] You describe your programming language using
rewrite rules in K.  They define tools to auto-derive rules in \href{http://www.kframework.org/index.php/Projects}{K}.

\item[{Program slicing}] ‘Galois connection on the traces’. This allows
you to find where bugs appeared.  People tend to look in the most
recent.  Imagine a call-graph of all the variables, so it gives you
a minimum trace, showing where your bug can be found.
\end{description}
\end{enumerate}
\subsection{Data course}
\label{sec:orga4ca4c3}
There's a new book available from the group affiliated with STAN.  It
doesn't go very far, but it has tons of examples.  They have data sets
about all sorts of stuff.  So the idea would be to take, e.g., the
notebook on linear regression, and go through\ldots{}

\subsubsection{Idea}
\label{sec:org147c40b}

Start with a method, then go through lots of examples.  Make this
consistent with the way we would teach HtDP.

``Here's a data set, here's a method that would make sense to apply.''

\subsubsection{A quandry}
\label{sec:org8e46abd}

Note that hand-coding of a curriculum vs making a general framework
that anyone can contribute to (e.g., to make their own curricula) are
pretty different things.  We will sort out this ambiguity later.

\subsubsection{Sources}
\label{sec:orgaa63b9e}

There are tons of great data sets, but the issue would be digging into
the details of some of them.  The real issue is coordinating.  We want
to start with e.g., intro to linear regression, then hierarchical
linear regression, and working up to things like Lotka-Voltera model.

\begin{itemize}
\item Datopian
\end{itemize}

\subsubsection{How to build up to this?}
\label{sec:orgbef27d0}

\begin{itemize}
\item E.g., setting up the pre-requisites of the platform
\item Setting up a tutorial on model building in a certain domain, get 10 people in the specialised tutorial, how is it received
\item This would start building up the group of people
\begin{itemize}
\item Using someone else's platform would be different from using our own platform
\item Which of these is the focus? (\textbf{Good question but let's have one or two sprints beforehand to see where things are going.})
\end{itemize}
\end{itemize}

\subsubsection{Assumptions}
\label{sec:orgfd001e1}

\begin{itemize}
\item Keep platform open source, assume people would want to use
\end{itemize}

\subsubsection{Comments}
\label{sec:orga844c62}

\begin{itemize}
\item Platform is quite a general word, but in a way we are trying to make something easier
\item The platform is just an interface to a piece of technology we build.  The core is really on the backend.
\item So the focus should be on the backend not on the javascript bits.
\item Maybe leverage more existing technologies for the platform, where building it basically means installing it.
\item Nextjournal: this looks good because they have UX designers to polish things
\item Cloud-based Emacs: Would allow you to back your instantiation as if Emacs is your operating system, 500GB instance on Google Cloud
\end{itemize}

\subsubsection{Status}
\label{sec:orgbf1dd2d}

\begin{itemize}
\item Cameron has code to set up a multicluster platform available off the shelf that we can start with
\item Ray has been doing similar things for personal use, though if this helps write biology papers.
\item What if our user interface was Emacs?
\begin{itemize}
\item Different keybindings; developers like Emacs or Vi\ldots{}
\item Org Bable exists \& we can refer to this for now
\end{itemize}
\end{itemize}

\subsubsection{Reference}
\label{sec:org8fc39d4}

\begin{itemize}
\item Michael Betancourt: Towards a principled bayesian workflow
\end{itemize}
\subsection{Paperspace DO NJ etc. Collaboratory}
\label{sec:org46df7c5}
This would be a potential user-facing product in which we could deploy
various curricula, share various tools for interacting with
scientific/computational models, and build a “knowledge hub” of people
who could do scientific work.
\section{BUSINESS DEVELOPMENT}
\label{sec:org82003db}
\subsection{Relationship to purpose}
\label{sec:orgf6de69d}

Understanding how the business activities relate to the purpose?  We
might do things that appear unrelated what we say at \textbf{Why not what} to
serve customer needs in the mean time.  However, if we do, we should
either come up with some reasoning about how this helps us address the
purpose, or revise our statement of purpose to reflect the current
reality.  This presumably isn’t hard to do, e.g., we could say “once
we have a successful business we will pour \emph{x\%} into research,” but in
any case we should clarify this.

\subsection{Roughly B2C}
\label{sec:org4d8a5e6}

\begin{itemize}
\item Launch some version of the Emacs Hyper Notebook as a cloud service. (Build it first and test it first.)
\item \textbf{Visual Interfaces}: Develop a user interface on top of more advanced data analysis tools. (The focus is on the infrastructure that allows you to convert a graph into a neural network or whatever.)
\item \textbf{Data course} (training format): Recruit people to take our course for a fee.
\item \textbf{Paperspace DO NJ etc. Collaboratory} (Edtech SaaS): People would build their own courses/projects on our software and pay for licensing.
\item \textbf{Teach arbitrary coding} (Edtech SaaS): People would use our tutoring system to improve their programming abilities.
\end{itemize}

\subsection{B2B}
\label{sec:org963cd3c}

\begin{itemize}
\item \textbf{Agent model} (software as a service format): We can run our agent model to generate new code or other insights. People can pay for compute plus a premium for quality.
\item \textbf{Probabilistic programming for scientific computing} (Consulting format): going around and creating customers by talking to businesses, saying “Using proababilistic programming — or other technologies — we can optimize this, this, this, and this, saving you this much money.”
\begin{itemize}
\item Many companies hardly use any AI, let alone deep learning. If you can hustle and sell things, this can work.
\item However, we don’t want to sell AI snake oil, so if we are going to do consulting it should be around topics that we’re actually experts on. For example, plausibly, we could talk about modelling \emph{documents} and \emph{workflows}.
\end{itemize}
\end{itemize}

\subsection{Different kinds of users}
\label{sec:org53e306a}

If we want to build a business, we should focus on who our target
users actually are, and what problems we can solve for them.
Typically we would build the business in a customer-centric way.  So,
for example, are the users/customers:

\begin{itemize}
\item Advanced STAN users, or,
\item People who don't know how to do data analysis but who can make graphs.
\end{itemize}

Broad categories of users are surveyed in the \textbf{Downstream}.

\subsection{Related work}
\label{sec:org5dc4856}

\begin{itemize}
\item Be wary of competing with things like Roam, though some level of competition is intrinsic in business.
\item “Roam scratches my itches for document and graph aware note taking pretty well.”
\end{itemize}
\section{RESEARCH OUTPUTS}
\label{sec:orgb36b931}
We would like to publish some papers, though as Deyan points out we
should only do this when we have high-quality results:

\begin{quote}
Deyan: \emph{Every paper that is published for the sake of an academic's publication record, rather than for its scientific merit, is potent fuel for science denialism. The short-term shortcuts for a personal career, when compounded, cause long-term harm to the scientific endeavor.}
\end{quote}

So, what can we do without shortcuts?

\subsection{Advances in tutoring systems for programming}
\label{sec:orgda706d8}
This would be a survey paper that would inform our efforts to \textbf{Teach arbitrary coding}.
Follow references, start with ‘AI and tutoring’.

\begin{enumerate}
\item (2014) ``An adaptation algorithm for an intelligent natural language tutoring system''
\item (2008) ``A novel approach for constructing conversational agents using sentence similarity measures''
\end{enumerate}
\subsection{Advances in knowledge mining from technical documents}
\label{sec:org7a41e9f}
This would be a survey paper that would inform our efforts on
\textbf{*Information extraction from SO Q\&A items} and the \textbf{Knowledge graph}
approach.  Note that if we can find survey papers that others have
done, that’s pretty much just as useful, and saves us a bunch of time.

\subsubsection{{\bfseries\sffamily STARTED} Reading ``Machine Knowledge'' paper\hfill{}\textsc{deyan}}
\label{sec:orgc9d4ad8}
\subsection{An ABM of the computer programming domain}
\label{sec:org2f1f96b}
This would be a paper writing up our agent model work.

The paper could also correspond to a “whitepaper” that talks about how
we are able to “mine” computer programs automatically.  This would
contribute to a long-term business in automated programming (and
potentially other kinds of automation work).
\section{Bottom}
\label{sec:org54dba62}
By the time we get to this point, we will have established some
impressive research outputs, a potentially profitable business, and a
teaching/upskilling platform for technical and scientific topics.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{org-roam-server-3oct2020.png}
\caption{Network view}
\end{figure}
\section{Downstream}
\label{sec:orgd6b1f45}
What do our potential users look like?

\subsection{Consulting clients}
\label{sec:org21da9c4}
We discussed the idea of doing consulting for clients who are
interested in using scientific models.

\begin{itemize}
\item \href{0caba40b-2561-4143-b2b1-55f3ddc3201b}{Play through again as a consulting client}
\end{itemize}
\subsection{Scientific software developers}
\label{sec:org169ee26}
We imagine some software developers consuming “tutorial” content we
produce, and improving their skills and abilities as a result.

\begin{itemize}
\item \href{0caba40b-2561-4143-b2b1-55f3ddc3201b}{Play through again as a scientific software developer}
\end{itemize}
\subsection{Automated tutoring system users}
\label{sec:orgdd7035a}
We imagine some students using AI software we develop.  In some cases
they could be “students”.  In other cases, they could already be
professional developers.

\begin{itemize}
\item \href{0caba40b-2561-4143-b2b1-55f3ddc3201b}{Play through again as an automated tutoring system user}
\end{itemize}
\subsection{Programmers}
\label{sec:org32d6b6c}
We imagine any programmer having some use for our tools.  “B2D”
(Business to Developer) is an emerging category of enterprise where we
can do interesting things.

\begin{itemize}
\item \href{0caba40b-2561-4143-b2b1-55f3ddc3201b}{Play through again as a programmer}
\end{itemize}
\section{Organisational infrastructure}
\label{sec:org90a4620}
This section is mildly-technical appendix.  It looks at our
organisational infrastructure itself, including simple things like the
technologies we use for communication, and more involved things like
“how we communicate” more broadly.  (This is a good candidate for
splitting off into its own separate wiki, if for no other reason than
that it takes up a lot of space in the generated PDF.)

\subsection{Schedule and activities}
\label{sec:orgdbd5e3c}

Presently we are meeting 20 minutes a day at 4PM UK time, 11AM
Eastern, on Discord for a “coffee chat”.

Previously we tried to maintain a schedule of longer meetings (UK
evenings):

\begin{itemize}
\item \textbf{Monday}: Seminar
\item \textbf{Wednesday}: Workshop
\item \textbf{Friday}: Studio
\end{itemize}

That seemed to be too many meetings.  Whatever we do about regularly
scheduled meetings, we might want to look at how to best pursue of
\textbf{*topics of mutual interest} such as:

\begin{itemize}
\item \textbf{Readings} on rewriting rules and production systems, and higher-dimensional graph-like things
\item \textbf{Business development} around open source, knowledge management, etc.
\item \textbf{Reviewing} the value add of Wiki ways of thinking and working, which we have a pretty broad range of experience with
\item \textbf{R\&D} around ‘lenses’ in ACT: structure for bi-directional transformations, to enable changes in a projection
\end{itemize}

So far, this Roadmap has gathered information on some of the topics
that have been discussed, but not all of the things that we could see
ourselves working on together.

As another activity we may want to get scheduled one or more sessions
focused on business stuff.

\subsection{Project orientation}
\label{sec:org4d39b30}

Some of this will be different depending on whether we think of this
as a “business”, or as “a business of some specific nature”: primarily
centring on “who does this business do business with?”

\begin{itemize}
\item \textbf{Status} - where is the project right now?
\begin{itemize}
\item Right now \emph{this overall project} is in a “project development” mode.
\item What are the (multiple) \emph{success indicators} or \emph{proof points} or \emph{failure indicators} for each of the projects? (E.g., going to the casino with \$20, you might quit when you get below \$10, you might leave when you get above \$50.) E.g., need of customers for X, our credibility in X?
\item For the various sub-projects: one relevant thing is “how long is it before thing is likely to make money?” (AKA, “Cross-over.”) Or “what else is needed for this to make money?”
\item In particular: maybe take a couple months to see how things are going with a given sub-project? This gives evidence of what we can produce when we work together. We might then ask, who else would care to pay for this?
\item We have listed 4 active projects (\url{https://miro.com/app/board/o9J\_kmPNvaQ=/}); maybe the blog is another one.
\end{itemize}
\item \textbf{Roles and Responsibilities} - \emph{who is handling the standard project roles, and what are they responsible for doing?}
\begin{itemize}
\item Each individual sub-project is likely to have different requirements (e.g., some may need 2 people, some will need 1, etc.)
\item If there’s more than one person involved it becomes a parallel architecture
\end{itemize}
\item \textbf{Goals} - \emph{What will this project achieve?}
\begin{itemize}
\item “If I do something valuable, the money will come later.”
\item Some of them we might be willing to take the risk of investing time and energy based on whether it looks directly useful to us.
\item Some, like a course, we may need the information about whether it’s likely to be taught.
\item Some could become a paper or the building block of a business: these can be small demo projects.
\item Alternatively, in a consulting mode, our role becomes understanding customer goals and helping rationalise work to fulfil them.
\end{itemize}
\item \textbf{Resource Requirements} - \emph{What (people, money, things) are needed to accomplish this project?  Where do they come from?}
\begin{itemize}
\item We each individually need some money, but it’s not totally clear that the \emph{company} needs some money.
\item If we wanted to replace any one of us with an employee, then we’d have to have some funding source.
\item If the number of person-hours for the goal is quite high, then it’s unlikely for the goal to be achieved without funding.
\item E.g., what would we need to be able to do consulting?
\end{itemize}
\item \textbf{People} - \emph{Who are the people working on this project? Who can I ask for more information? How can I best get in touch with them?}
\begin{itemize}
\item If we were to be doing consulting, then it becomes about serving specific customer needs.
\end{itemize}
\item \textbf{Approach} - \emph{What is the overall strategy for accomplishing this project?}
\begin{itemize}
\item Whatever we choose (e.g., consulting vs product development) we should choose it based on some data and analysis.
\item Wherever we are now, the question is what’s needed to move ahead.
\end{itemize}

\item \textbf{Workplan and Timeline} - What are the specific tasks needed to accomplish our goals? When might they happen? Who / what / when (in agile, we specify two).
\begin{itemize}
\item Joe needs some job soon!
\item To do consulting we’d need to figure out customer need and credibility
\item To make progress on the AI directions we need some version of all the things up and running!
\end{itemize}
\item \textbf{Communication Norms} - how have the project participants agreed to stay in touch? what, where and how often are regular meetings? Special ceremonies?
\begin{itemize}
\item In 2 months we’ll have 2 more months of experience.  So we could then assess things.
\item In advance of that, we might start to understand the expections about how we would gather the data.
\item It should be pretty much fun, and if it’s not we’re kind of doing it wrong?
\item On an ongoing basis we should be able to check whether what we’re doing is effectively addressing the goals we have
\end{itemize}
\item \textbf{Sponsor} - \emph{the person who requires the output of the project and has allocated the resources for it (aka Customer in agile)}
\begin{itemize}
\item So far we’re all sponsoring our own work on sweat equity
\item While also trying to be helpful \& respectful to each other
\item EF was the sponsor at one time
\item Joe provided chips and dip but the event was strictly BYOB\ldots{} as long as we’re here we’ll make the best out of.  Polka time!
\end{itemize}
\item \textbf{Project Manager} - the person responsible for the drumbeat and tempo of the project, and for its administrative details, including good project management hygiene
\item \textbf{Lead} - the person responsible to the Sponsor for making sure the project is accomplished and to the Team for making sure they are able to accomplish the project
\begin{itemize}
\item Ray: project to build bridges between participants (e.g., systems bio, category theory, stats); this is related to the “transdisciplinary design” course
\item Joe: I’m less technically sophisticated
\end{itemize}
\item \textbf{Team} - people working on the project
\begin{itemize}
\item Everyone will have some constraints (like need \$40K per year if it takes more than 20 hours per week)
\end{itemize}
\end{itemize}

\subsubsection{Project Management Hygiene}
\label{sec:orgbcdd720}

\begin{itemize}
\item set SMART goals (Specific, Measurable, Achievable, Relevant and Time-based)
\item understand tasks required to accomplish goals, then set realistic timeline
\item create project plan in wiki
\item regular, frequent check-ins to iterate plan (goal, priorities, etc.) if necessary
\item after-action reviews at the end of project, including reflection/writeup of positives and deltas
\item experienced, well-oiled teams requires less strict project management hygiene
\item new, less-organized, or heterogenous teams require more attention to careful project management hygiene
\end{itemize}

\subsubsection{{\bfseries\sffamily TODO} Make a list of actual topics of interest\hfill{}\textsc{ALL}}
\label{sec:org3e82fe2}
If we were just doing “content production” we might think of a list of
chapters to write, or podcasts to produce. However, maybe those ways
of thinking and working don’t apply comfortably here.

\subsubsection{{\bfseries\sffamily TODO} Make a project analysis of active projects\hfill{}\textsc{joe:ray}}
\label{sec:org0531625}

\subsection{Technology}
\label{sec:orgdda5026}

Does \url{https://github.com/orgs/exp2exp/projects/1} conflict, replace, or
serve a different function compared with Org mode agenda items?  

\subsubsection{{\bfseries\sffamily TODO} Figure out Github project(s) vs Org todos\hfill{}\textsc{joe:cameron}}
\label{sec:orgefe40a1}

\subsection{Discord server}
\label{sec:org36ee261}
We set up a Discord server that we’re using for our meetings.  This
invite link should not expire: \url{https://discord.gg/pArjt4p}

(We also have a Zulip server set up, but currently we’re using it
less.)
\subsection{OBS recordings}
\label{sec:orgbf2f311}
We talked about creating asyncronous recordings (screencasts,
audio). We also talked about possibly putting the audio recordings
into a threaded voice mail forum, but that's a somewhat different
application.

\subsection{Code sharing platform}
\label{sec:orgb2f6260}
For now we have a Github organisation (\url{https://github.com/exp2exp}), as
well as a separate repo that contains these Org Roam notes, among
other things.  This could potentially be improved or upgraded in
various ways.

\subsubsection{Comments}
\label{sec:org8038543}

\begin{itemize}
\item Nextjournal is interesting
\item It's like a Jupyter notebook
\item It's like Org Bable so you can run code in any language within the same environment
\item If I need to add a bash cell to a Julia notebook, it adds a kernel as needed at the run time
\item If I install a bunch of libraries, and save the current environment in a docker container, you can import it
\item It doesn't yet have an easy way to make an app?
\end{itemize}

\subsubsection{What if you had a browser based version of Org Bable?}
\label{sec:orgde549d7}

\begin{itemize}
\item You could have your notebook, backed by the ability to use Emacs
\end{itemize}

\subsubsection{Examples}
\label{sec:orgb432374}

\begin{itemize}
\item Setting up a data science experiment
\item Wadler et al. course in Agda in NextJournal
\item But you can't easily treat this as ‘Org Roam’ (no bi-directional things)
\end{itemize}

\subsubsection{Next evolution}
\label{sec:org0813e82}

We need a basic code sharing platform to get to work.  The next
evolution might look like what we’ve been calling the “Emacs Hyper
Notebook”?  However, some contributors are not interested in using
Emacs for everything.  And we can’t assume that users would be
interested in it either!
\subsection{Wiki}
\label{sec:org8bba941}
The public facing version of these notes is available on a simple web
interface, created by firn: \href{https://exp2exp.github.io/}{https://exp2exp.github.io/}. This mirrors
the contents of our Org Roam directory.  Editing is explained below.

We can also view the contents of Org Roam in a linear form as PDF
document\ldots{} or view the currently active tasks using Org Agenda.  In
the future we may want to have several different “upstream” locations,
based on several different small-scale wikis, all feeding into this
one location.  That’s not hard to set up.  Contents can also be
browsed in a graphical form either with the built in \texttt{org-roam-graph}
functionality, or by installing Org Roam Server and running
\texttt{org-roam-server-mode}.

We can potentially improve on all of this further, bulding something
like Metacademy.  For now, we describe how to use this simple Org Roam
based wiki.

\subsubsection{Access}
\label{sec:orgf5849de}

Obtain the sources by cloning the repo at \href{https://github.com/exp2exp/exp2exp.github.io}{https://github.com/exp2exp/exp2exp.github.io}.

\begin{verbatim}
git clone git@github.com:exp2exp/exp2exp.github.io.git
\end{verbatim}

(See below for an alternative.)

\subsubsection{Mob branch on repo.or.cz}
\label{sec:org1002e74}

We’re mirroring the repo to an environment that allows anonymous
commits (without need for further permissioning).  If want to
contribute anonymously, info on that is here: \href{https://bit.ly/2EQRHEF}{https://bit.ly/2EQRHEF}

You can review commits to the mob branch here: \href{https://repo.or.cz/arxana.git/shortlog/refs/heads/mob}{https://repo.or.cz/arxana.git/shortlog/refs/heads/mob}

\subsubsection{Setup}
\label{sec:org3103c07}

Install Org Roam if needed (\texttt{M-x package-install RET org-roam RET}).

Subsequently, add this to your Emacs configuration:

\begin{verbatim}
(require 'org-roam)
(setq org-roam-directory (concat "/home/"
                          (getenv "USER")
                          "/exp2exp/"))
(setq org-roam-completion-system 'helm)
(define-key org-roam-mode-map (kbd "C-c n l") #'org-roam)
(define-key org-roam-mode-map (kbd "C-c n f") #'org-roam-find-file)
(define-key org-roam-mode-map (kbd "C-c n b") #'org-roam-switch-to-buffer)
(define-key org-roam-mode-map (kbd "C-c n g") #'org-roam-graph)
(define-key org-mode-map (kbd "C-c n i") #'org-roam-insert)
(org-roam-mode +1)
\end{verbatim}
\subsubsection{Bonus feature: org-roam-checkout}
\label{sec:org6a86b24}

If you regularly use your own separate Org Roam setup, you can use
this simple context switcher to move between the two.  Keep track of
the various separate Org Roam installations with \texttt{org-roam-library}
and then switch between them interactively with \texttt{org-roam-checkout}.

\begin{verbatim}
(defvar org-roam-library `(,(concat "/home/" (getenv "USER") "/exp2exp/")
                           ,(concat "/home/" (getenv "USER") "/org-roam/")))

(defun org-roam-checkout ()
  (interactive)
  (let ((ctx org-roam-directory))
    (if (eq (length org-roam-library) 1)
        ;; Still go ahead and set the variable in this case!
        (progn (setq org-roam-directory (car org-roam-library))
               (message "You only have one choice for org-roam-directory defined."))
      (let ((lib (completing-read "Choose a volume: " org-roam-library)))
        (when lib
          (setq org-roam-directory lib))))
    ;; assuming the user changes context, let’s also prompt them
    ;; to choose a new file in that context
    (when (not (eq ctx org-roam-directory))
      (org-roam-find-file))))
\end{verbatim}

\subsubsection{Interaction}
\label{sec:org3eaa788}

Use the \texttt{C-c n f} keyboard command to add new disconnected nodes to
the graph, or use \texttt{C-c n i} to create a page and insert a wiki-style
link, like \texttt{[[New Page]]}. Follow links with \texttt{C-c C-o}. Display the
graph structure with \texttt{C-c n g}.  It may be necessary to run \texttt{M-x
org-roam-db-build-cache} to get the graph to match reality.  Add and
commit new or modified files with git, along with \texttt{org-roam.db}, and
push them to the repo.

\subsubsection{Tags}
\label{sec:orgae0c994}

Some of the nodes have \texttt{\#+roam\_tags} set:

\begin{center}
\begin{tabular}{ll}
\textbf{code} & \textbf{meaning}\\
\hline
HL & High level\\
CDN & Can do now\\
LRD & Longer R\&D cycle\\
HD & Has dependencies\\
RR & Research Review\\
RO & Research Output\\
OTS & Off the shelf\\
SH & Stakeholder\\
AN & Annex\\
\end{tabular}
\end{center}

Some of the files also have a \texttt{\#+CATEGORY} set.

\subsubsection{Pairing}
\label{sec:orgcdd4746}

For syncronized browsing and editing with \href{https://github.com/tjim/lockstep}{lockstep.el}:

\begin{verbatim}
ssh pair@178.79.174.58
PW: <ASK JOE FOR THE PASSWORD>
emacsclient -a '' -t
M-x lockstep
\end{verbatim}

To open up a real-time collaboration (with multiple cursors), use
\href{https://code.librehq.com/qhong/crdt.el}{crdt.el}, first to serve the buffer:

\begin{verbatim}
M-x crdt-serve-buffer
\end{verbatim}

And then, from your client, to connect:

\begin{verbatim}
M-x crdt-connect
\end{verbatim}

\subsubsection{Linearizing}
\label{sec:org67cb6b3}
To turn this map into something we can reliably use, let’s try to
linearize it.

To downsample from Org Roam (save as \texttt{\textasciitilde{}/bin/roam2org.sh} and make it
executable):

\begin{verbatim}
#! /bin/bash

emacs --batch -l ~/bin/downsample-org-roam.el --eval "(combine-files)" "$@"
\end{verbatim}

Here are the working parts (save as \texttt{\textasciitilde{}/bin/downsample-org-roam.el}):

\begin{verbatim}
(defun downsample ()
  "Process an Org Roam buffer for inclusion in a standard Org file.
Changes title to header, and increase indentation of existing headers.
Changes file links to internal links."
  (if (looking-at "^#\\+TITLE:")
      (replace-match "*"))
  (forward-line 1)
  (if (looking-at "^#\\+roam_tags:\\(.*\\)")
      (replace-match ":PROPERTIES:
  :tag:\\1
  :END:"))
  (while (re-search-forward "^\\*" nil t)
    (replace-match "**"))
  (goto-char (point-min))
  (while (re-search-forward "\\[\\[file:\\([^]]*\\)\\]\\[\\([^]]*\\)\\]\\]" nil t)
    (replace-match "[[*\\2][\\2]]"))
  (buffer-substring-no-properties (point-min) (point-max)))

(defun combine-org-roam-files (&rest args)
"Combine a list of files, specified as ARGs.
The files are to be found in `org-roam-directory'."
  (apply #'concat
         (mapcar (lambda (file)
                   (save-window-excursion
                     (find-file (concat org-roam-directory file))
                     (let ((contents (buffer-substring-no-properties (point-min)
                                                                     (point-max))))
                       (with-temp-buffer (insert contents)
                                         (goto-char (point-min))
                                         (downsample)))))
                 (or (car args) (nthcdr 5 command-line-args)))))
\end{verbatim}

\subsubsection{Backlog}
\label{sec:orgaa3ffdf}
Part of the idea with a backlog is to go from most-doable, starting
with work in progress, to least-doable and potentially vague.  Here,
then, is one approximate linearization that may or may not meet that
description!

Note, this is duplicated in the index file, probably for sanity we
should pick one and automate the derived version from there!

\begin{verbatim}
(defvar files-to-combine
'("20200810131435-hyperreal_enterprises.org"
"20200810132653-top.org"
"20200905124558-why_not_what.org"
 "20200909195629-teach_arbitrary_coding.org"
 "20200810135851-how_to_design_programs_with_if.org"
"20200905124405-construct_critique_improve_models_of_the_creative_process.org"
  "20200905125342-emacs_hyper_notebook.org"
  "emacs_jupyter_remote_debugging.org"
"20200905125023-which_model_construction_process_works_as_a_whole.org"
 "20200905131027-information_extraction_from_so_q_a_items.org"
"20200905131918-knowledge_graph.org"
"20200905124432-underlying_foundation.org"
 "20200905125713-category_theoretic_glue.org"
 "20200905131656-probabilistic_programming_for_scientific_modelling.org"
"20201003205523-potential_products.org"
 "20200905130423-agent_model.org"
 "20200817172825-recommender_system.org"
 "20200810135457-visual_interfaces.org"
 "20200814203551-data_course.org"
 "20200905132603-paperspace_do_nj_etc_collaboratory.org"
"20200814210243-business_development.org"
"20200905134325-research_outputs.org"
 "20200810135325-advances_in_tutoring_systems_for_programming.org"
 "20200810135403-advances_in_knowledge_mining_from_technical_documents.org"
 "20200905132334-an_abm_of_the_computer_programming_domain.org"
"20200906003704-bottom.org"
 "20201003164408-downstream.org"
 "20201003165500-consulting_clients.org"
 "20201003170312-open_source_developers.org"
 "20201003170333-tutoring_students.org"
 "20201003171011-programmers.org"
"20200810135126-organisational_infrastructure.org"
 "20200810135619-discord_server.org"
 "20200811185435-obs_recordings.org"
 "20200814193042-code_sharing_platform.org"
 "20200912223428-wiki.org"
 "20201003164100-forum.org"
 "20200814195259-blog.org"
"sfi/sfi.org"
 "sfi/gather_data_via_stack_exchange_apis.org"
 "sfi/argumentation_theoretic_analysis.org"
 "sfi/process_model_analysis.org"
 "sfi/ml_nlp_bootcamp.org"
 "sfi/initial_ml_baseline_e_g_match_q_a.org"
 "sfi/hierarchical_ml_for_content_extraction.org"
 "sfi/active_inference_bootcamp.org"
 "sfi/agent_modelling_and_sandbox_setup.org"
 "sfi/curate_koans_and_develop_solver.org"
 "sfi/study_with_crowdsourced_exercises.org"
 "sfi/study_with_agent_written_questions.org"
 "sfi/publication_ijcai.org"
)
"An ordered list of files to combine in our export.
This is where the order of presentation in the downstream org file
and derived PDF is defined.")
\end{verbatim}

To combine the files, run:
\begin{verbatim}
(combine-org-roam-files files-to-combine)
\end{verbatim}

To get the indicative nesting (shown by spaces above) to be replicated
at the org level, run the following at the top of the exported
compilation:

\begin{verbatim}
(defun indent-org-roam-export ()
  "Utility function to increase indention for selected trees."
  (org-map-entries (lambda ()
                     ;; don’t demote the top level items and their sub-items
                     (let ((tag (org-entry-get nil "tag")))
                       (if (and tag (string= (car (split-string tag)) "HL"))
                           (progn (org-end-of-subtree)
                                  (setq org-map-continue-from (point)))
                         (org-do-demote))))
                   nil 'file))
\end{verbatim}

Lastly, to rebuild the PDF, all of this can be done with one swift
action.

\begin{verbatim}
(defun rebuild-org-roam-pdf ()
  "Build an org file and PDF compiling `files-to-combine'."
  (interactive)
  (save-excursion (find-file (concat org-roam-directory
                                     "/manual/combined.org"))
    (goto-char (point-min))
    (search-forward "# IMPORT")
    (let ((beg (point)))
      (delete-region (point) (point-max))
      (insert "\n" (combine-org-roam-files files-to-combine))
      (goto-char beg)
      (indent-org-roam-export)
      (org-latex-export-to-pdf))))
\end{verbatim}

\subsubsection{Publishing to the web}
\label{sec:orgd9ff861}

Publishing with Firn is simple:

\begin{verbatim}
firn build
\end{verbatim}

Then commit and push.

\subsubsection{Reviewing progress}
\label{sec:orgd57314f}

Something like the following should be all that’s get a high-level
overview of progress on active tasks, sourcing information directly
from the Org Roam files.  Add the following to your emacs
initialisation script (e.g., \texttt{\textasciitilde{}/.emacs}), evaluate it, and then run
\texttt{C-c r} to load up the fun.  This may not be the perfect presentation
yet but it gives an idea.

\begin{verbatim}
(setq org-todo-keywords
      '((sequence "TODO" "STARTED" "BLOCKED" "BACKBURNER" "FROZEN"
                  "|" "DONE" "DEFERRED" "WONTFIX")))

(setq org-agenda-sorting-strategy '((todo todo-state-down category-down)))

(setq org-agenda-files '("~/exp2exp/"))

(defun org-scrum-board ()
  (interactive)
  (org-todo-list "TODO|STARTED|BLOCKED|BACKBURNER|FROZEN|DONE|DEFERRED|WONTFIX"))

(global-set-key (kbd "C-c r") 'org-scrum-board)
\end{verbatim}

This view can then be further filtered by regexp (e.g., your name) by
pressing \texttt{=}.

\subsubsection{{\bfseries\sffamily DONE} Package downsamping code separately\hfill{}\textsc{joe}}
\label{sec:org287cb0a}
\subsubsection{{\bfseries\sffamily WONTFIX} Update the repo instructions to reference this file\hfill{}\textsc{joe}}
\label{sec:orgfe01f26}

\subsection{Forum}
\label{sec:org64b26a1}
We talked about using Wikum as a forum, because we liked the idea of a
workflow based on summarising discussions. There’s now a demo instance
set up that we can use, here:

\url{http://wikum.org/visualization\_flags?id=590\&owner=holtzermann17}

\subsubsection{Could we incorporate the ideas directly in Org or Org Roam?}
\label{sec:org8c508c3}

Perhaps we could incorporate some Wikum ideas right into the wiki
here.  The idea would be to treat the top paragraph on each page as a
summary, and then add discussion threads below.  We’d want some system
of tags that indicated whether the summary was validated or now.
(Note the the original WikiWikiWeb did not have separate talk pages!
I don’t know if they practiced robust summarisation, either.)

\begin{enumerate}
\item REMARK\hfill{}\textsc{joe}
\label{sec:org7f6da4a}
This is an “inline task,” via \texttt{(require 'org-inlinetask)}.  There
doesn’t seem to be support for nested or threaded tasks, but maybe we
would have use for non-threaded forum discussions at the end of any
page in the Wiki.  Incidentally, for those curious, the formatting of
the \LaTeX~export is controlled by
\texttt{org-latex-format-inlinetask-function}.
\item END
\label{sec:orgac59e19}
\end{enumerate}

\subsubsection{{\bfseries\sffamily TODO} What might our summarisation workflow look like?\hfill{}\textsc{ALL}}
\label{sec:org40214cf}

Since we’re pretty actively updating our \textbf{Discord} and pretty happy
using it, maybe people who are working on Active Projects would be
willing to summarise on the wiki, say, weekly?  And contribute to a
monthly group blog post?
\subsection{Blog}
\label{sec:org0199004}
This is a public window on our experiments, available at
\href{https://exp2exp.com}{https://exp2exp.com}.

Presently, we’re still figuring out what the work flow and contents of
the blog will look like.  The kinds of people to whom we wish to
appear credible are described in \textbf{Downstream}, and presumably whatever
we put online should match what we think they will want to know.

\begin{quote}
Zans: \emph{If I implemented as I read things, it would be a pretty interesting blog. There could be a huge market of people interested in following this, this would give a pool of people who know who we are. This is a nice goal b/c it doesn't focus on the product\ldots{} but it's a deliverable, made up of smaller deliverables, and a concrete benefit.}
\end{quote}

\section{Joe’s Santa Fe Institute proposal (Redux)}
\label{sec:org5d1cbca}
This is some content trying to build a linear plan.

From within the Hyperreal Enterprises repo this should connect to
\hyperref[sec:orgce48d63]{Top}.

\subsection{Gather data via Stack Exchange APIs}
\label{sec:orgff89354}

This is just a matter of downloading the data in bulk.  We’ve also seen that some of the data is available in a bulk download. Tim did some work to load it into a machine learning framework.
\subsection{Argumentation-theoretic analysis}
\label{sec:org2aef24c}

I’ve started to look at some of the Q\&A items to see whether there’s
anything there we can extract.

This isn’t yet the same as an argumentation-theoretic analysis, but I
can imagine returning to this Q\&A stuff through the lens of the
earlier papers, and see what we could do to argument-mine them.
\subsection{Process model analysis}
\label{sec:org29f35a9}

This is about making a model of the process of programming, per
Monocl, which I think we’ve been starting to understand a bit better
through HtDP recently.
\subsection{ML/NLP bootcamp}
\label{sec:orgb9764be}

I got some insights from both Tim and Deyan about what is directly
possible to do with existing tools.  We didn’t yet progress beyond
some initial “failed” experiments and partial work. However, in
principle we could go back to it and try to do Q\&A matching.  That’s a
low-level task.
\subsection{Initial ML baseline, e.g., match Q-A}
\label{sec:org939a481}

This remains a pretty straightforwardly “doable” task if we were to
get things loaded up.

After taking a stab at things within the the HEL sessions, I could
presumably take that as a curriculum to be able to get this running
after several months (with adequate help from Tim and Deyan).

However, it’s less obviously useful\ldots{} if we can’t do the
“hierarchical ML” next step.
\subsection{Hierarchical ML for content extraction}
\label{sec:orgbe4c87a}

I guess part of this would be to do first Coarse Discourse style
detections, then move from that to more specific models.

During the HEL sessions I don’t think we’ve made any directly tangible
progress on this goal.

I did find references to \emph{CROKAGE}, which I should follow up on.

Still, maybe there are some alternative ways to make progress here
that should be thought about.
\subsection{Active Inference bootcamp}
\label{sec:orgf9ca909}

Cameron talked a bit about active inference, and his Bayesian stats
background is relevant to making sense of what’s going on in here.
Lots of other papers are available, including some by Beren Millidge
if we wanted to start making models of agents.

We could also think about these models in terms of Tangled Program
Graphs or some other reinforcement learning paradigm.  E.g., Zans and
I talked about making an upvoting bot.  If we could moreover learn the
actual features that go into good questions and answers, then those
could be used on the generative side too.
\subsection{Agent modelling and sandbox setup}
\label{sec:org9f617b7}

This seems to be the main outcome of the Active Inference bootcamp.

Could we set up a simpler agent learning paradigm, and progressively
run it in long epochs, in which the agents learn more complicated
skills each time?  E.g., learn how to upvote, learn how to retrieve
relevant concepts, learn how to structure them into sentences and
paragraphs?

Maybe it’s worth looking around at some of the other Stack Exchange
sites to get inspired, or have a think about what domains the Q\&A
approach might be especially suitable for.  (E.g., are there any open
source SQuAD systems that would naturally lend themselves to agent
modelling?)

Or, what about the question of turning Stack Exchange into a set of
rewrite rules first, and basing the agents on those rules?  If we
think about things in terms of rewriting, then maybe each rewriting
step could be viewed as a Q/A pair.  So then, we could look at any
open source rewrite system and try to give a score to rules based on
how often they are used.
\subsection{Curate koans and develop solver}
\label{sec:orgae51712}

The first part seems relatively straightforward: we already have
questions available from sites like 4Clojure.  But the solver hasn’t
really been that much in scope for any of the things we’ve been
working on yet!  However, Ray looked at some classic work on
rule-based solutions to subtraction problems, and I’d say that
something along these lines could be created for solving Clojure koans
(each of which is mainly meant to teach a specific rule, anyway).  I’m
sure it would be helpful for me to get more practice, and this time,
include a careful writeup of the ‘rules’ I follow.
\subsection{Study with crowdsourced exercises}
\label{sec:orgec74edf}

“Crowdsourced reading comprehension questions and simple exercises
derived from existing Q\&A would provide a further route to
evaluation.”

So the idea here would be to pay people to come up with some
SQuAD-like questions and answers based on existing Stack Exchange
problems.  This would help build a catalogue of the kinds of things
we’re looking for inside of the Q\&A items.
\subsection{Study with agent-written questions}
\label{sec:org9449b43}

Can agents come up with questions to ask about a given question that
break it down into more do-able components?

“Asking questions about Stack Overflow questions.”

What sorts of Q/A structures might go in to reading and comprehending
a given question?  Maybe, again, we could think in terms of rewrite
rules.  “Here is a portion of text that is unclear.  Let’s try to see
what the author was actually trying to say.”
\subsection{Publication: IJCAI}
\label{sec:org4c132ed}

If some of the foregoing ideas “worked” then we would presumably have
some nice things to write up for a publication.  In fact, a bunch of
the other ideas that were in my plan would probably be better saved
for future work.  Maybe things, like institutions, should be
foregrounded.  But, I can see how the plan I submitted to SFI probably
came across as overly ambitious and unrealistic.  Maybe the basic plan
above would have to be spread out over 2 years.

On the other hand, some of these ideas do look like fun exploratory
kinds of topics, which should maybe be thought about in some
brainstorming sessions, just to keep things fresh.  So, for now, these
could become slips of paper that we pull out of a jar at a party to
discuss?

\subsubsection{Other possible future work}
\label{sec:orgad5c8ee}

\begin{itemize}
\item \textbf{M13}  Institution modelling using IAD
\item \textbf{M14}  Integrate themes from SFI collaborators
\item \textbf{M15}  Develop infrastructure for contributors
\item \textbf{M16}  Agents writing agents
\item \textbf{M17}  Agents writing institutions
\item \textbf{M18}  Organise first contest
\item \textbf{M19}  Publication: Artificial Intelligence
\item \textbf{M20}  Integrate with Github API
\item \textbf{M21}  Integrate themes from SFI collaborators
\item \textbf{M22}  Study in an online tutoring application
\item \textbf{M23}  Publication: Science
\item \textbf{M24}  Time off and plan Year 3
\end{itemize}
\end{document}
